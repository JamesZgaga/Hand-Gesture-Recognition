{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4e201b-599a-40fc-972b-956b132c7fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®é›†é…ç½®:\n",
      "è®­ç»ƒé›†è·¯å¾„: /mnt/MCP/hagrid_dataset_512/train\n",
      "éªŒè¯é›†è·¯å¾„: /mnt/MCP/hagrid_dataset_512/val\n",
      "æµ‹è¯•é›†è·¯å¾„: /mnt/MCP/hagrid_dataset_512/test\n",
      "ç±»åˆ«æ•°é‡: 9\n",
      "ç±»åˆ«åç§°: ['call', 'fist', 'like', 'ok', 'one', 'palm', 'rock', 'three', 'two up']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "# è¯»å–YAMLé…ç½®\n",
    "with open('/mnt/MCP/hagrid_dataset_512/data_hagrid.yaml', 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"æ•°æ®é›†é…ç½®:\")\n",
    "print(f\"è®­ç»ƒé›†è·¯å¾„: {data_config['train']}\")\n",
    "print(f\"éªŒè¯é›†è·¯å¾„: {data_config['val']}\") \n",
    "print(f\"æµ‹è¯•é›†è·¯å¾„: {data_config['test']}\")\n",
    "print(f\"ç±»åˆ«æ•°é‡: {data_config['nc']}\")\n",
    "print(f\"ç±»åˆ«åç§°: {data_config['names']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be29ab82-8777-4e35-bab4-7bb6b8f60b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "è®­ç»ƒé›†å›¾åƒæ–‡ä»¶æ•°é‡: 0\n",
      "è®­ç»ƒé›†æ ‡æ³¨æ–‡ä»¶æ•°é‡: 181526\n",
      "å‰5ä¸ªå›¾åƒæ–‡ä»¶: []\n",
      "å‰5ä¸ªæ ‡æ³¨æ–‡ä»¶: ['672a263d-1478-4739-a012-264f0f1fdab4.txt', 'd97f87c8-86cf-41dc-8b07-dcb5e290fd2f.txt', 'ff05ec2a-6a9e-46e8-a44f-b17a6029f2d2.txt', '0f0ef7ba-ea87-4f24-9760-053a79c104c5.txt', 'a5af9e97-90db-4704-bf8b-65ab8414bc00.txt']\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥è®­ç»ƒé›†\n",
    "train_images_dir = data_config['train']\n",
    "train_labels_dir = '/mnt/MCP/hagrid_dataset_512/train_labels'\n",
    "\n",
    "# åˆ—å‡ºéƒ¨åˆ†æ–‡ä»¶æŸ¥çœ‹å¯¹åº”å…³ç³»\n",
    "image_files = [f for f in os.listdir(train_images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "label_files = []\n",
    "for class_name in data_config['names']:\n",
    "    class_label_dir = os.path.join(train_labels_dir, class_name)\n",
    "    if os.path.exists(class_label_dir):\n",
    "        label_files.extend([f for f in os.listdir(class_label_dir) if f.endswith('.txt')])\n",
    "\n",
    "print(f\"\\nè®­ç»ƒé›†å›¾åƒæ–‡ä»¶æ•°é‡: {len(image_files)}\")\n",
    "print(f\"è®­ç»ƒé›†æ ‡æ³¨æ–‡ä»¶æ•°é‡: {len(label_files)}\")\n",
    "print(f\"å‰5ä¸ªå›¾åƒæ–‡ä»¶: {image_files[:5]}\")\n",
    "print(f\"å‰5ä¸ªæ ‡æ³¨æ–‡ä»¶: {label_files[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f7f0eca-ede6-474f-95cd-a63cac8005d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒé›†æ ‡æ³¨æ–‡ä»¶å†…å®¹æ£€æŸ¥:\n",
      "\n",
      "call ç±»åˆ«çš„æ ‡æ³¨æ–‡ä»¶ç¤ºä¾‹:\n",
      "  1338a65d-11bf-4303-84a7-83eb2c0010d2.txt: 0 0.47650076 0.4459387 0.2477095 0.28360232\n",
      "  6d098009-e931-48fb-ad7e-8a6c181db8ad.txt: 0 0.247361705 0.39347237999999995 0.16327209 0.14845196\n",
      "  d5befba0-efa8-4abb-8e93-6ca3193e3905.txt: 0 0.52857424 0.42971766 0.24858702 0.17368398\n",
      "\n",
      "fist ç±»åˆ«çš„æ ‡æ³¨æ–‡ä»¶ç¤ºä¾‹:\n",
      "  2b3c6173-9fcc-4d4d-874b-34a10d130fda.txt: \n",
      "  4bbac49d-f563-401a-b252-a42e1ec5cd8f.txt: \n",
      "  571030ae-7fd4-4d93-96aa-956edd547402.txt: \n",
      "\n",
      "like ç±»åˆ«çš„æ ‡æ³¨æ–‡ä»¶ç¤ºä¾‹:\n",
      "  e3519c4a-50ba-4697-a667-ed05598ccf03.txt: 1 0.49135113 0.6253823900000001 0.16813338 0.12331332\n",
      "  b0948178-007a-4956-bcf1-192461975f27.txt: 1 0.611560285 0.666343355 0.12264315 0.23673049\n",
      "  8252ce7d-9768-48bf-a0c6-707a9fa0ca1e.txt: 1 0.59534673 0.46707862499999997 0.1403737 0.09393287\n",
      "\n",
      "ok ç±»åˆ«çš„æ ‡æ³¨æ–‡ä»¶ç¤ºä¾‹:\n",
      "  2d2b125a-cfa8-46e1-af05-508f323ec6b1.txt: \n",
      "  77fd08b8-c97b-45f0-936b-85342ed59fab.txt: \n",
      "  03761954-6623-4bce-b442-b9324210faa1.txt: \n",
      "\n",
      "one ç±»åˆ«çš„æ ‡æ³¨æ–‡ä»¶ç¤ºä¾‹:\n",
      "  2fd621a7-94d8-4cc3-9218-6593f2104293.txt: 2 0.32972978 0.30241065 0.17552356 0.325592\n",
      "  08eef81a-c59d-4264-9c85-6c9455560983.txt: 2 0.26638467 0.363866065 0.15355572 0.19800779\n",
      "  3178d4ed-9d9c-4df7-a6ea-3fc4e259f06a.txt: 2 0.911749715 0.3809225 0.12931767 0.12042556\n",
      "\n",
      "palm ç±»åˆ«çš„æ ‡æ³¨æ–‡ä»¶ç¤ºä¾‹:\n",
      "  b31a7695-cdb3-4509-813b-eb7ac2ce79ba.txt: \n",
      "  2b47714d-7024-4b19-9134-0ae2764ab055.txt: \n",
      "  5f8a8f81-11c7-4a1a-aaba-7cb990dabe4c.txt: \n",
      "\n",
      "rock ç±»åˆ«çš„æ ‡æ³¨æ–‡ä»¶ç¤ºä¾‹:\n",
      "  277df527-01f9-4954-93c0-e17fdea61d7e.txt: \n",
      "  919cbc01-dfe7-490f-8e52-0b04dbab933a.txt: \n",
      "  0ca224f5-5534-468e-acb2-3d7cfd9a06d7.txt: \n",
      "\n",
      "three ç±»åˆ«çš„æ ‡æ³¨æ–‡ä»¶ç¤ºä¾‹:\n",
      "  62e5fc7f-e621-4208-9ff4-fbcae7831471.txt: \n",
      "  c0450e46-6ea2-4662-8c82-afd91c0456f9.txt: \n",
      "  9681b111-d89c-4780-987d-a33547747961.txt: \n"
     ]
    }
   ],
   "source": [
    "# éšæœºæ£€æŸ¥å‡ ä¸ªæ ‡æ³¨æ–‡ä»¶çš„å†…å®¹\n",
    "import random\n",
    "\n",
    "def check_annotation_files(labels_dir, class_names, num_samples=3):\n",
    "    for class_name in class_names:\n",
    "        class_label_dir = os.path.join(labels_dir, class_name)\n",
    "        if os.path.exists(class_label_dir):\n",
    "            txt_files = [f for f in os.listdir(class_label_dir) if f.endswith('.txt')]\n",
    "            if txt_files:\n",
    "                sample_files = random.sample(txt_files, min(num_samples, len(txt_files)))\n",
    "                print(f\"\\n{class_name} ç±»åˆ«çš„æ ‡æ³¨æ–‡ä»¶ç¤ºä¾‹:\")\n",
    "                for file in sample_files:\n",
    "                    file_path = os.path.join(class_label_dir, file)\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        content = f.read().strip()\n",
    "                        print(f\"  {file}: {content}\")\n",
    "\n",
    "# æ£€æŸ¥è®­ç»ƒé›†æ ‡æ³¨\n",
    "print(\"è®­ç»ƒé›†æ ‡æ³¨æ–‡ä»¶å†…å®¹æ£€æŸ¥:\")\n",
    "check_annotation_files(train_labels_dir, data_config['names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b0f20d-3df4-4a5f-b10d-bc01e080ed91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ–°çš„YAMLé…ç½®æ–‡ä»¶å·²ä¿å­˜è‡³: /mnt/MCP/hagrid_dataset_512/data_hagrid_subdir.yaml\n",
      "é…ç½®å†…å®¹:\n",
      "\n",
      "# Hagridæ‰‹åŠ¿æ•°æ®é›† - é€‚åº”å­ç›®å½•ç»“æ„\n",
      "path: /mnt/MCP/hagrid_dataset_512  # æ•°æ®é›†æ ¹ç›®å½•\n",
      "\n",
      "# è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•é›†è·¯å¾„ï¼ˆç›¸å¯¹äºpathï¼‰\n",
      "train: train  # å›¾åƒåœ¨ train/<class_name>/ ä¸­\n",
      "val: val      # å›¾åƒåœ¨ val/<class_name>/ ä¸­  \n",
      "test: test    # å›¾åƒåœ¨ test/<class_name>/ ä¸­\n",
      "\n",
      "# ç±»åˆ«æ•°é‡\n",
      "nc: 9\n",
      "\n",
      "# ç±»åˆ«åç§°ï¼ˆä¸ç›®å½•ååŒ¹é…ï¼‰\n",
      "names: ['call', 'fist', 'like', 'ok', 'one', 'palm', 'rock', 'three', 'two_up']\n",
      "\n",
      "# æ ‡ç­¾è·¯å¾„ï¼ˆç›¸å¯¹äºpathï¼‰\n",
      "train_labels: train_labels\n",
      "val_labels: val_labels\n",
      "test_labels: test_labels\n",
      "\n",
      "# æ³¨æ„ï¼šæ­¤é…ç½®éœ€è¦è‡ªå®šä¹‰æ•°æ®åŠ è½½å™¨\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºæ–°çš„YAMLé…ç½®ï¼Œé€‚åº”å­ç›®å½•ç»“æ„\n",
    "new_yaml_content = f\"\"\"\n",
    "# Hagridæ‰‹åŠ¿æ•°æ®é›† - é€‚åº”å­ç›®å½•ç»“æ„\n",
    "path: /mnt/MCP/hagrid_dataset_512  # æ•°æ®é›†æ ¹ç›®å½•\n",
    "\n",
    "# è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•é›†è·¯å¾„ï¼ˆç›¸å¯¹äºpathï¼‰\n",
    "train: train  # å›¾åƒåœ¨ train/<class_name>/ ä¸­\n",
    "val: val      # å›¾åƒåœ¨ val/<class_name>/ ä¸­  \n",
    "test: test    # å›¾åƒåœ¨ test/<class_name>/ ä¸­\n",
    "\n",
    "# ç±»åˆ«æ•°é‡\n",
    "nc: {len(corrected_names)}\n",
    "\n",
    "# ç±»åˆ«åç§°ï¼ˆä¸ç›®å½•ååŒ¹é…ï¼‰\n",
    "names: {corrected_names}\n",
    "\n",
    "# æ ‡ç­¾è·¯å¾„ï¼ˆç›¸å¯¹äºpathï¼‰\n",
    "train_labels: train_labels\n",
    "val_labels: val_labels\n",
    "test_labels: test_labels\n",
    "\n",
    "# æ³¨æ„ï¼šæ­¤é…ç½®éœ€è¦è‡ªå®šä¹‰æ•°æ®åŠ è½½å™¨\n",
    "\"\"\"\n",
    "\n",
    "# ä¿å­˜æ–°çš„YAMLæ–‡ä»¶\n",
    "new_yaml_path = '/mnt/MCP/hagrid_dataset_512/data_hagrid_subdir.yaml'\n",
    "with open(new_yaml_path, 'w') as f:\n",
    "    f.write(new_yaml_content)\n",
    "\n",
    "print(f\"æ–°çš„YAMLé…ç½®æ–‡ä»¶å·²ä¿å­˜è‡³: {new_yaml_path}\")\n",
    "print(\"é…ç½®å†…å®¹:\")\n",
    "print(new_yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "669bed3a-9613-4f1e-b63e-e3f0100cea08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒé›†æ ·æœ¬æ•°: 65729\n",
      "æ‰‹åŠ¿ç±»åˆ«: ['ok', 'call', 'palm', 'fist', 'like', 'rock', 'three', 'one', 'two_up']\n",
      "ç±»åˆ«æ˜ å°„: {'ok': 0, 'call': 1, 'palm': 2, 'fist': 3, 'like': 4, 'rock': 5, 'three': 6, 'one': 7, 'two_up': 8}\n",
      "\n",
      "æ ·æœ¬å›¾åƒå½¢çŠ¶: torch.Size([3, 224, 224])\n",
      "è¾¹ç•Œæ¡†ä¿¡æ¯: tensor([[256.5231, 226.3248, 372.9645, 338.8653,   0.0000]])\n",
      "æ–‡ä»¶å¤¹ç±»åˆ«ID: 1\n",
      "å¯¹åº”ç±»åˆ«åç§°: call\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class GestureDataset(Dataset):\n",
    "    \"\"\"æ‰‹åŠ¿æ•°æ®é›†ç±»ï¼Œç”¨äºåŠ è½½å’Œå¤„ç†æ‰‹åŠ¿å›¾åƒåŠå¯¹åº”çš„YOLOæ ¼å¼æ ‡æ³¨\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–æ•°æ®é›†\n",
    "        :param root_dir: æ•°æ®é›†æ ¹ç›®å½•\n",
    "        :param split: æ•°æ®é›†ç±»å‹ï¼Œå¯é€‰'train', 'test', 'val'\n",
    "        :param transform: å›¾åƒå˜æ¢å‡½æ•°\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        # å›¾åƒå’Œæ ‡ç­¾ç›®å½•\n",
    "        self.images_dir = os.path.join(root_dir, split)\n",
    "        self.labels_dir = os.path.join(root_dir, f\"{split}_labels\")\n",
    "        \n",
    "        # è·å–æ‰€æœ‰æ‰‹åŠ¿ç±»åˆ«ï¼ˆæ’é™¤zipæ–‡ä»¶ï¼‰\n",
    "        self.categories = [d for d in os.listdir(self.images_dir) \n",
    "                          if os.path.isdir(os.path.join(self.images_dir, d)) \n",
    "                          and not d.endswith('.zip')]\n",
    "        self.category_to_idx = {cat: i for i, cat in enumerate(self.categories)}\n",
    "        self.idx_to_category = {v: k for k, v in self.category_to_idx.items()}\n",
    "        \n",
    "        # æ”¶é›†æ‰€æœ‰æ ·æœ¬è·¯å¾„\n",
    "        self.samples = self._collect_samples()\n",
    "        \n",
    "    def _collect_samples(self):\n",
    "        \"\"\"æ”¶é›†æ‰€æœ‰å›¾åƒå’Œå¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶è·¯å¾„\"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        for category in self.categories:\n",
    "            img_cat_dir = os.path.join(self.images_dir, category)\n",
    "            label_cat_dir = os.path.join(self.labels_dir, category)\n",
    "            \n",
    "            # ç¡®ä¿æ ‡ç­¾ç›®å½•å­˜åœ¨\n",
    "            if not os.path.exists(label_cat_dir):\n",
    "                print(f\"è­¦å‘Šï¼šæ ‡ç­¾ç›®å½•ä¸å­˜åœ¨ {label_cat_dir}ï¼Œè·³è¿‡è¯¥ç±»åˆ«\")\n",
    "                continue\n",
    "            \n",
    "            # éå†å›¾åƒæ–‡ä»¶\n",
    "            for img_filename in os.listdir(img_cat_dir):\n",
    "                # åªå¤„ç†å›¾åƒæ–‡ä»¶\n",
    "                if img_filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                    img_path = os.path.join(img_cat_dir, img_filename)\n",
    "                    \n",
    "                    # ç”Ÿæˆå¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶åï¼ˆåŒåä¸åŒæ‰©å±•åï¼‰\n",
    "                    img_basename = os.path.splitext(img_filename)[0]\n",
    "                    label_filename = f\"{img_basename}.txt\"\n",
    "                    label_path = os.path.join(label_cat_dir, label_filename)\n",
    "                    \n",
    "                    # æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "                    if os.path.exists(label_path) and os.path.getsize(label_path) > 0:\n",
    "                        samples.append((img_path, label_path, self.category_to_idx[category]))\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def _parse_yolo_label(self, label_path, img_width, img_height):\n",
    "        \"\"\"\n",
    "        è§£æYOLOæ ¼å¼çš„æ ‡ç­¾æ–‡ä»¶\n",
    "        YOLOæ ¼å¼è¯´æ˜ï¼šæ¯è¡ŒåŒ…å« ç±»åˆ«ID x_center y_center width height \n",
    "                     å…¶ä¸­x_center, y_center, width, heightå‡ä¸ºå½’ä¸€åŒ–åˆ°[0,1]çš„å€¼\n",
    "                     ä»¥å›¾åƒå·¦ä¸Šè§’ä¸ºåŸç‚¹\n",
    "        :param label_path: æ ‡ç­¾æ–‡ä»¶è·¯å¾„\n",
    "        :param img_width: å›¾åƒå®½åº¦\n",
    "        :param img_height: å›¾åƒé«˜åº¦\n",
    "        :return: è§£æåçš„è¾¹ç•Œæ¡† (xmin, ymin, xmax, ymax, class_id)\n",
    "        \"\"\"\n",
    "        boxes = []\n",
    "        \n",
    "        with open(label_path, 'r') as f:\n",
    "            for line_num, line in enumerate(f.readlines(), 1):\n",
    "                line = line.strip()\n",
    "                if not line:  # è·³è¿‡ç©ºè¡Œ\n",
    "                    continue\n",
    "                \n",
    "                # åˆ†å‰²å­—æ®µï¼ˆæ”¯æŒç©ºæ ¼æˆ–åˆ¶è¡¨ç¬¦åˆ†éš”ï¼‰\n",
    "                parts = line.split()\n",
    "                if len(parts) != 5:\n",
    "                    print(f\"è­¦å‘Šï¼š{label_path} ç¬¬{line_num}è¡Œæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡è¯¥è¡Œ\")\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # è§£æå­—æ®µï¼šç¬¬ä¸€ä¸ªæ˜¯ç±»åˆ«IDï¼Œåé¢å››ä¸ªæ˜¯åæ ‡\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center = float(parts[1])\n",
    "                    y_center = float(parts[2])\n",
    "                    width = float(parts[3])\n",
    "                    height = float(parts[4])\n",
    "                except ValueError:\n",
    "                    print(f\"è­¦å‘Šï¼š{label_path} ç¬¬{line_num}è¡Œæ•°å€¼è§£æé”™è¯¯ï¼Œè·³è¿‡è¯¥è¡Œ\")\n",
    "                    continue\n",
    "                \n",
    "                # æ£€æŸ¥å½’ä¸€åŒ–å€¼æ˜¯å¦åœ¨åˆç†èŒƒå›´\n",
    "                if not (0 <= x_center <= 1 and 0 <= y_center <= 1 and \n",
    "                        0 < width <= 1 and 0 < height <= 1):\n",
    "                    print(f\"è­¦å‘Šï¼š{label_path} ç¬¬{line_num}è¡Œåæ ‡è¶…å‡ºåˆç†èŒƒå›´ï¼Œè·³è¿‡è¯¥è¡Œ\")\n",
    "                    continue\n",
    "                \n",
    "                # è½¬æ¢ä¸ºç»å¯¹åæ ‡ (xmin, ymin, xmax, ymax)\n",
    "                xmin = (x_center - width / 2) * img_width\n",
    "                ymin = (y_center - height / 2) * img_height\n",
    "                xmax = (x_center + width / 2) * img_width\n",
    "                ymax = (y_center + height / 2) * img_height\n",
    "                \n",
    "                # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…\n",
    "                xmin = max(0, xmin)\n",
    "                ymin = max(0, ymin)\n",
    "                xmax = min(img_width, xmax)\n",
    "                ymax = min(img_height, ymax)\n",
    "                \n",
    "                boxes.append([xmin, ymin, xmax, ymax, class_id])\n",
    "        \n",
    "        return np.array(boxes, dtype=np.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        img_path, label_path, category_id = self.samples[idx]\n",
    "        \n",
    "        # è¯»å–å›¾åƒ\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"æ— æ³•è¯»å–å›¾åƒ: {img_path}\")\n",
    "        \n",
    "        # è½¬æ¢ä¸ºRGBæ ¼å¼ï¼ˆcv2é»˜è®¤è¯»å–ä¸ºBGRï¼‰\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        img_height, img_width = image.shape[:2]\n",
    "        \n",
    "        # è§£ææ ‡ç­¾\n",
    "        boxes = self._parse_yolo_label(label_path, img_width, img_height)\n",
    "        \n",
    "        # åº”ç”¨å˜æ¢\n",
    "        if self.transform:\n",
    "            # æ³¨æ„ï¼šå¦‚æœéœ€è¦åŒæ—¶å˜æ¢è¾¹ç•Œæ¡†ï¼Œéœ€è¦è‡ªå®šä¹‰å˜æ¢é€»è¾‘\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'boxes': torch.from_numpy(boxes),  # è¾¹ç•Œæ¡†åŠæ ‡ç­¾å†…çš„ç±»åˆ«ID\n",
    "            'category_id': torch.tensor(category_id, dtype=torch.long),  # æ–‡ä»¶å¤¹å¯¹åº”çš„ç±»åˆ«ID\n",
    "            'image_path': img_path,\n",
    "            'label_path': label_path\n",
    "        }\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_root = \"/mnt/MCP/hagrid_dataset_512\"\n",
    "    \n",
    "    # å®šä¹‰å›¾åƒå˜æ¢\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),  # ä»numpyæ•°ç»„è½¬æ¢ä¸ºPILå›¾åƒ\n",
    "        transforms.Resize((224, 224)),  # è°ƒæ•´å¤§å°\n",
    "        transforms.ToTensor(),  # è½¬æ¢ä¸ºTensorå¹¶å½’ä¸€åŒ–åˆ°[0,1]\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNetå‡å€¼\n",
    "                             std=[0.229, 0.224, 0.225])   # ImageNetæ ‡å‡†å·®\n",
    "    ])\n",
    "    \n",
    "    # åˆ›å»ºæ•°æ®é›†\n",
    "    train_dataset = GestureDataset(\n",
    "        root_dir=dataset_root,\n",
    "        split='train',\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    print(f\"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}\")\n",
    "    print(f\"æ‰‹åŠ¿ç±»åˆ«: {train_dataset.categories}\")\n",
    "    print(f\"ç±»åˆ«æ˜ å°„: {train_dataset.category_to_idx}\")\n",
    "    \n",
    "    # æµ‹è¯•ä¸€ä¸ªæ ·æœ¬\n",
    "    if len(train_dataset) > 0:\n",
    "        sample = train_dataset[0]\n",
    "        print(f\"\\næ ·æœ¬å›¾åƒå½¢çŠ¶: {sample['image'].shape}\")\n",
    "        print(f\"è¾¹ç•Œæ¡†ä¿¡æ¯: {sample['boxes']}\")\n",
    "        print(f\"æ–‡ä»¶å¤¹ç±»åˆ«ID: {sample['category_id']}\")\n",
    "        print(f\"å¯¹åº”ç±»åˆ«åç§°: {train_dataset.idx_to_category[sample['category_id'].item()]}\")\n",
    "    \n",
    "    # åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=8,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        collate_fn=lambda x: {  # å¤„ç†å¯å˜é•¿åº¦çš„è¾¹ç•Œæ¡†\n",
    "            'image': torch.stack([i['image'] for i in x]),\n",
    "            'boxes': [i['boxes'] for i in x],\n",
    "            'category_id': torch.tensor([i['category_id'] for i in x]),\n",
    "            'image_path': [i['image_path'] for i in x]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a934e3b3-f949-4d2a-969a-3ae40d7c9e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "å¼€å§‹æ£€æŸ¥ train æ•°æ®é›†...\n",
      "==================================================\n",
      "\n",
      "æ£€æŸ¥ç±»åˆ«: ok\n",
      "  å›¾åƒæ€»æ•°: 23131, æœ‰æ•ˆå›¾åƒ: 23131\n",
      "  æ ‡ç­¾æ€»æ•°: 23131, æœ‰æ•ˆæ ‡ç­¾: 0\n",
      "  å›¾åƒæ— æ ‡ç­¾: 0, æ ‡ç­¾æ— å›¾åƒ: 0\n",
      "\n",
      "æ£€æŸ¥ç±»åˆ«: call\n",
      "  å›¾åƒæ€»æ•°: 20034, æœ‰æ•ˆå›¾åƒ: 20034\n",
      "  æ ‡ç­¾æ€»æ•°: 20034, æœ‰æ•ˆæ ‡ç­¾: 20034\n",
      "  å›¾åƒæ— æ ‡ç­¾: 0, æ ‡ç­¾æ— å›¾åƒ: 0\n",
      "\n",
      "æ£€æŸ¥ç±»åˆ«: palm\n",
      "  å›¾åƒæ€»æ•°: 23654, æœ‰æ•ˆå›¾åƒ: 23654\n",
      "  æ ‡ç­¾æ€»æ•°: 23654, æœ‰æ•ˆæ ‡ç­¾: 0\n",
      "  å›¾åƒæ— æ ‡ç­¾: 0, æ ‡ç­¾æ— å›¾åƒ: 0\n",
      "\n",
      "æ£€æŸ¥ç±»åˆ«: fist\n",
      "  å›¾åƒæ€»æ•°: 23480, æœ‰æ•ˆå›¾åƒ: 23480\n",
      "  æ ‡ç­¾æ€»æ•°: 23480, æœ‰æ•ˆæ ‡ç­¾: 0\n",
      "  å›¾åƒæ— æ ‡ç­¾: 0, æ ‡ç­¾æ— å›¾åƒ: 0\n",
      "\n",
      "æ£€æŸ¥ç±»åˆ«: like\n",
      "  å›¾åƒæ€»æ•°: 23197, æœ‰æ•ˆå›¾åƒ: 23197\n",
      "  æ ‡ç­¾æ€»æ•°: 23197, æœ‰æ•ˆæ ‡ç­¾: 0\n",
      "  å›¾åƒæ— æ ‡ç­¾: 0, æ ‡ç­¾æ— å›¾åƒ: 0\n",
      "\n",
      "æ£€æŸ¥ç±»åˆ«: rock\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 247\u001b[0m\n\u001b[1;32m    244\u001b[0m dataset_root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/MCP/hagrid_dataset_512\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# æ‰§è¡Œæ£€æŸ¥\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_root\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# å¦‚æœéœ€è¦ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# import json\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# with open('dataset_report.json', 'w', encoding='utf-8') as f:\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m#     json.dump(report, f, ensure_ascii=False, indent=2)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 81\u001b[0m, in \u001b[0;36mcheck_dataset\u001b[0;34m(root_dir, splits)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶ï¼ˆæ”¯æŒå¸¸è§æ ¼å¼ï¼‰\u001b[39;00m\n\u001b[1;32m     80\u001b[0m img_extensions \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.gif\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     82\u001b[0m     f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(cat_img_dir)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(img_extensions) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cat_img_dir, f))\n\u001b[1;32m     84\u001b[0m ]\n\u001b[1;32m     85\u001b[0m num_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(images)\n\u001b[1;32m     86\u001b[0m split_report[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_images\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_images\n",
      "Cell \u001b[0;32mIn[3], line 83\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶ï¼ˆæ”¯æŒå¸¸è§æ ¼å¼ï¼‰\u001b[39;00m\n\u001b[1;32m     80\u001b[0m img_extensions \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.gif\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     81\u001b[0m images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     82\u001b[0m     f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(cat_img_dir)\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(img_extensions) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_img_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m ]\n\u001b[1;32m     85\u001b[0m num_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(images)\n\u001b[1;32m     86\u001b[0m split_report[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_images\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_images\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/genericpath.py:30\u001b[0m, in \u001b[0;36misfile\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path is a regular file\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     st \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "def check_dataset(root_dir, splits=['train', 'test', 'val']):\n",
    "    \"\"\"\n",
    "    å…¨é¢æ£€æŸ¥æ•°æ®é›†æƒ…å†µ\n",
    "    :param root_dir: æ•°æ®é›†æ ¹ç›®å½•\n",
    "    :param splits: éœ€è¦æ£€æŸ¥çš„æ•°æ®é›†åˆ†å‰²ï¼ˆé»˜è®¤æ£€æŸ¥trainã€testã€valï¼‰\n",
    "    \"\"\"\n",
    "    # å­˜å‚¨æ‰€æœ‰æ£€æŸ¥ç»“æœ\n",
    "    report = {}\n",
    "    \n",
    "    for split in splits:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"å¼€å§‹æ£€æŸ¥ {split} æ•°æ®é›†...\")\n",
    "        print(f\"{'='*50}\\n\")\n",
    "        \n",
    "        # åˆå§‹åŒ–å½“å‰åˆ†å‰²çš„æŠ¥å‘Š\n",
    "        split_report = {\n",
    "            'total_categories': 0,\n",
    "            'categories': [],\n",
    "            'total_images': 0,\n",
    "            'total_labels': 0,\n",
    "            'image_label_mismatch': [],  # å›¾åƒä¸æ ‡ç­¾ä¸åŒ¹é…çš„æƒ…å†µ\n",
    "            'invalid_images': [],        # æ— æ•ˆ/æŸåçš„å›¾åƒ\n",
    "            'invalid_labels': [],        # æ ¼å¼é”™è¯¯çš„æ ‡ç­¾\n",
    "            'empty_labels': [],          # ç©ºæ ‡ç­¾æ–‡ä»¶\n",
    "            'category_stats': defaultdict(dict),  # æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†ç»Ÿè®¡\n",
    "            'image_size_dist': defaultdict(int),  # å›¾åƒå°ºå¯¸åˆ†å¸ƒ\n",
    "            'label_class_dist': defaultdict(int)  # æ ‡ç­¾ä¸­ç±»åˆ«IDåˆ†å¸ƒ\n",
    "        }\n",
    "        \n",
    "        # å›¾åƒå’Œæ ‡ç­¾æ ¹ç›®å½•\n",
    "        images_root = os.path.join(root_dir, split)\n",
    "        labels_root = os.path.join(root_dir, f\"{split}_labels\")\n",
    "        \n",
    "        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨\n",
    "        if not os.path.exists(images_root):\n",
    "            print(f\"é”™è¯¯ï¼š{split} å›¾åƒç›®å½•ä¸å­˜åœ¨ - {images_root}\")\n",
    "            report[split] = split_report\n",
    "            continue\n",
    "        if not os.path.exists(labels_root):\n",
    "            print(f\"é”™è¯¯ï¼š{split} æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨ - {labels_root}\")\n",
    "            report[split] = split_report\n",
    "            continue\n",
    "        \n",
    "        # è·å–æ‰€æœ‰ç±»åˆ«ï¼ˆæ’é™¤zipæ–‡ä»¶å’Œéç›®å½•ï¼‰\n",
    "        categories = [\n",
    "            d for d in os.listdir(images_root)\n",
    "            if os.path.isdir(os.path.join(images_root, d)) and not d.endswith('.zip')\n",
    "        ]\n",
    "        split_report['total_categories'] = len(categories)\n",
    "        split_report['categories'] = categories\n",
    "        \n",
    "        if not categories:\n",
    "            print(f\"è­¦å‘Šï¼š{split} æ•°æ®é›†æœªå‘ç°ä»»ä½•ç±»åˆ«ç›®å½•\")\n",
    "            report[split] = split_report\n",
    "            continue\n",
    "        \n",
    "        # ç±»åˆ«åç§°åˆ°IDçš„æ˜ å°„ï¼ˆç”¨äºæ ¡éªŒæ ‡ç­¾ä¸­çš„ç±»åˆ«IDï¼‰\n",
    "        cat2id = {cat: i for i, cat in enumerate(categories)}\n",
    "        \n",
    "        # éå†æ¯ä¸ªç±»åˆ«\n",
    "        for cat in categories:\n",
    "            print(f\"æ£€æŸ¥ç±»åˆ«: {cat}\")\n",
    "            cat_img_dir = os.path.join(images_root, cat)\n",
    "            cat_label_dir = os.path.join(labels_root, cat)\n",
    "            \n",
    "            # æ£€æŸ¥ç±»åˆ«æ ‡ç­¾ç›®å½•æ˜¯å¦å­˜åœ¨\n",
    "            if not os.path.exists(cat_label_dir):\n",
    "                print(f\"  è­¦å‘Šï¼š{cat} æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨ - {cat_label_dir}\")\n",
    "                split_report['category_stats'][cat]['exists'] = False\n",
    "                continue\n",
    "            split_report['category_stats'][cat]['exists'] = True\n",
    "            \n",
    "            # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶ï¼ˆæ”¯æŒå¸¸è§æ ¼å¼ï¼‰\n",
    "            img_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.gif')\n",
    "            images = [\n",
    "                f for f in os.listdir(cat_img_dir)\n",
    "                if f.lower().endswith(img_extensions) and os.path.isfile(os.path.join(cat_img_dir, f))\n",
    "            ]\n",
    "            num_images = len(images)\n",
    "            split_report['total_images'] += num_images\n",
    "            split_report['category_stats'][cat]['num_images'] = num_images\n",
    "            \n",
    "            # è·å–æ‰€æœ‰æ ‡ç­¾æ–‡ä»¶\n",
    "            labels = [\n",
    "                f for f in os.listdir(cat_label_dir)\n",
    "                if f.lower().endswith('.txt') and os.path.isfile(os.path.join(cat_label_dir, f))\n",
    "            ]\n",
    "            num_labels = len(labels)\n",
    "            split_report['total_labels'] += num_labels\n",
    "            split_report['category_stats'][cat]['num_labels'] = num_labels\n",
    "            \n",
    "            # æ£€æŸ¥å›¾åƒä¸æ ‡ç­¾çš„æ–‡ä»¶ååŒ¹é…ï¼ˆæ’é™¤æ‰©å±•åï¼‰\n",
    "            img_basenames = {os.path.splitext(f)[0] for f in images}\n",
    "            label_basenames = {os.path.splitext(f)[0] for f in labels}\n",
    "            \n",
    "            # æœ‰å›¾åƒä½†æ— å¯¹åº”æ ‡ç­¾\n",
    "            img_no_label = img_basenames - label_basenames\n",
    "            if img_no_label:\n",
    "                for basename in img_no_label:\n",
    "                    img_path = os.path.join(cat_img_dir, f\"{basename}{[e for e in img_extensions if f'{basename}{e}' in images][0]}\")\n",
    "                    split_report['image_label_mismatch'].append(f\"å›¾åƒæ— å¯¹åº”æ ‡ç­¾: {img_path}\")\n",
    "            split_report['category_stats'][cat]['img_no_label'] = len(img_no_label)\n",
    "            \n",
    "            # æœ‰æ ‡ç­¾ä½†æ— å¯¹åº”å›¾åƒ\n",
    "            label_no_img = label_basenames - img_basenames\n",
    "            if label_no_img:\n",
    "                for basename in label_no_img:\n",
    "                    label_path = os.path.join(cat_label_dir, f\"{basename}.txt\")\n",
    "                    split_report['image_label_mismatch'].append(f\"æ ‡ç­¾æ— å¯¹åº”å›¾åƒ: {label_path}\")\n",
    "            split_report['category_stats'][cat]['label_no_img'] = len(label_no_img)\n",
    "            \n",
    "            # æ£€æŸ¥å›¾åƒæœ‰æ•ˆæ€§å’Œå°ºå¯¸\n",
    "            valid_images = 0\n",
    "            for img_file in images:\n",
    "                img_path = os.path.join(cat_img_dir, img_file)\n",
    "                try:\n",
    "                    # å°è¯•ç”¨OpenCVè¯»å–\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is None:\n",
    "                        # å°è¯•ç”¨PILè¯»å–ï¼ˆå¤„ç†æŸäº›ç‰¹æ®Šæ ¼å¼ï¼‰\n",
    "                        with Image.open(img_path) as pil_img:\n",
    "                            pil_img.verify()  # éªŒè¯å›¾åƒå®Œæ•´æ€§\n",
    "                        split_report['invalid_images'].append(f\"OpenCVæ— æ³•è¯»å–ï¼Œä½†PILå¯è¯†åˆ«: {img_path}\")\n",
    "                    else:\n",
    "                        h, w = img.shape[:2]\n",
    "                        split_report['image_size_dist'][f\"{w}x{h}\"] += 1\n",
    "                        valid_images += 1\n",
    "                except Exception as e:\n",
    "                    split_report['invalid_images'].append(f\"æŸåçš„å›¾åƒ: {img_path} (é”™è¯¯: {str(e)})\")\n",
    "            split_report['category_stats'][cat]['valid_images'] = valid_images\n",
    "            \n",
    "            # æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶æœ‰æ•ˆæ€§\n",
    "            valid_labels = 0\n",
    "            for label_file in labels:\n",
    "                label_path = os.path.join(cat_label_dir, label_file)\n",
    "                \n",
    "                # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºæ–‡ä»¶\n",
    "                if os.path.getsize(label_path) == 0:\n",
    "                    split_report['empty_labels'].append(f\"ç©ºæ ‡ç­¾æ–‡ä»¶: {label_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # è§£ææ ‡ç­¾å†…å®¹\n",
    "                try:\n",
    "                    with open(label_path, 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                    \n",
    "                    valid_line = True\n",
    "                    for line_num, line in enumerate(lines, 1):\n",
    "                        line = line.strip()\n",
    "                        if not line:\n",
    "                            continue\n",
    "                        \n",
    "                        parts = line.split()\n",
    "                        if len(parts) != 5:\n",
    "                            split_report['invalid_labels'].append(\n",
    "                                f\"æ ‡ç­¾æ ¼å¼é”™è¯¯ï¼ˆå­—æ®µæ•°ä¸å¯¹ï¼‰: {label_path} ç¬¬{line_num}è¡Œ\"\n",
    "                            )\n",
    "                            valid_line = False\n",
    "                            break\n",
    "                        \n",
    "                        # æ£€æŸ¥æ•°å€¼æ ¼å¼\n",
    "                        try:\n",
    "                            class_id = int(parts[0])\n",
    "                            x_center = float(parts[1])\n",
    "                            y_center = float(parts[2])\n",
    "                            width = float(parts[3])\n",
    "                            height = float(parts[4])\n",
    "                        except ValueError:\n",
    "                            split_report['invalid_labels'].append(\n",
    "                                f\"æ ‡ç­¾æ•°å€¼é”™è¯¯: {label_path} ç¬¬{line_num}è¡Œ\"\n",
    "                            )\n",
    "                            valid_line = False\n",
    "                            break\n",
    "                        \n",
    "                        # æ£€æŸ¥å½’ä¸€åŒ–èŒƒå›´\n",
    "                        if not (0 <= x_center <= 1 and 0 <= y_center <= 1 and\n",
    "                                0 < width <= 1 and 0 < height <= 1):\n",
    "                            split_report['invalid_labels'].append(\n",
    "                                f\"æ ‡ç­¾åæ ‡è¶…å‡ºèŒƒå›´: {label_path} ç¬¬{line_num}è¡Œ\"\n",
    "                            )\n",
    "                            valid_line = False\n",
    "                            break\n",
    "                        \n",
    "                        # è®°å½•æ ‡ç­¾ä¸­çš„ç±»åˆ«IDåˆ†å¸ƒ\n",
    "                        split_report['label_class_dist'][class_id] += 1\n",
    "                        \n",
    "                        # æ£€æŸ¥æ ‡ç­¾ç±»åˆ«IDæ˜¯å¦ä¸æ–‡ä»¶å¤¹ç±»åˆ«åŒ¹é…ï¼ˆå¦‚æœéœ€è¦ä¸¥æ ¼åŒ¹é…ï¼‰\n",
    "                        # if class_id != cat2id[cat]:\n",
    "                        #     split_report['invalid_labels'].append(\n",
    "                        #         f\"æ ‡ç­¾ç±»åˆ«IDä¸æ–‡ä»¶å¤¹ä¸åŒ¹é…: {label_path} ç¬¬{line_num}è¡Œ (é¢„æœŸ{cat2id[cat]}, å®é™…{class_id})\"\n",
    "                        #     )\n",
    "                        #     valid_line = False\n",
    "                        #     break\n",
    "                    \n",
    "                    if valid_line:\n",
    "                        valid_labels += 1\n",
    "                \n",
    "                except Exception as e:\n",
    "                    split_report['invalid_labels'].append(f\"æ ‡ç­¾æ–‡ä»¶è¯»å–é”™è¯¯: {label_path} (é”™è¯¯: {str(e)})\")\n",
    "            \n",
    "            split_report['category_stats'][cat]['valid_labels'] = valid_labels\n",
    "            print(f\"  å›¾åƒæ€»æ•°: {num_images}, æœ‰æ•ˆå›¾åƒ: {valid_images}\")\n",
    "            print(f\"  æ ‡ç­¾æ€»æ•°: {num_labels}, æœ‰æ•ˆæ ‡ç­¾: {valid_labels}\")\n",
    "            print(f\"  å›¾åƒæ— æ ‡ç­¾: {len(img_no_label)}, æ ‡ç­¾æ— å›¾åƒ: {len(label_no_img)}\\n\")\n",
    "        \n",
    "        # ä¿å­˜å½“å‰åˆ†å‰²çš„æŠ¥å‘Š\n",
    "        report[split] = split_report\n",
    "        \n",
    "        # è¾“å‡ºå½“å‰åˆ†å‰²çš„æ±‡æ€»ä¿¡æ¯\n",
    "        print(f\"\\n{split} æ•°æ®é›†æ±‡æ€»:\")\n",
    "        print(f\"  ç±»åˆ«æ•°é‡: {split_report['total_categories']}\")\n",
    "        print(f\"  æ€»å›¾åƒæ•°é‡: {split_report['total_images']}\")\n",
    "        print(f\"  æ€»æ ‡ç­¾æ•°é‡: {split_report['total_labels']}\")\n",
    "        print(f\"  å›¾åƒæ ‡ç­¾ä¸åŒ¹é…: {len(split_report['image_label_mismatch'])}\")\n",
    "        print(f\"  æ— æ•ˆ/æŸåå›¾åƒ: {len(split_report['invalid_images'])}\")\n",
    "        print(f\"  æ— æ•ˆæ ‡ç­¾æ–‡ä»¶: {len(split_report['invalid_labels'])}\")\n",
    "        print(f\"  ç©ºæ ‡ç­¾æ–‡ä»¶: {len(split_report['empty_labels'])}\")\n",
    "        \n",
    "        # è¾“å‡ºå›¾åƒå°ºå¯¸åˆ†å¸ƒï¼ˆå‰5ç§æœ€å¸¸è§çš„å°ºå¯¸ï¼‰\n",
    "        print(\"\\n  å¸¸è§å›¾åƒå°ºå¯¸ (å®½xé«˜):\")\n",
    "        sorted_sizes = sorted(split_report['image_size_dist'].items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        for size, count in sorted_sizes:\n",
    "            print(f\"    {size}: {count} å¼ \")\n",
    "        \n",
    "        # è¾“å‡ºæ ‡ç­¾ä¸­ç±»åˆ«IDåˆ†å¸ƒ\n",
    "        print(\"\\n  æ ‡ç­¾ä¸­ç±»åˆ«IDåˆ†å¸ƒ:\")\n",
    "        for class_id, count in sorted(split_report['label_class_dist'].items()):\n",
    "            print(f\"    ç±»åˆ«ID {class_id}: {count} æ¬¡\")\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"æ•°æ®é›†æ£€æŸ¥å®Œæˆï¼\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # æ•°æ®é›†æ ¹ç›®å½•ï¼ˆè¯·æ ¹æ®å®é™…è·¯å¾„ä¿®æ”¹ï¼‰\n",
    "    dataset_root = \"/mnt/MCP/hagrid_dataset_512\"\n",
    "    \n",
    "    # æ‰§è¡Œæ£€æŸ¥\n",
    "    report = check_dataset(dataset_root)\n",
    "    \n",
    "    # å¦‚æœéœ€è¦ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶\n",
    "    # import json\n",
    "    # with open('dataset_report.json', 'w', encoding='utf-8') as f:\n",
    "    #     json.dump(report, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7929af2c-f381-41dc-8604-b04df65224e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š æ•°æ®é›†ç»“æ„åˆ†æ\n",
      "==================================================\n",
      "\n",
      "æ•°æ®é›†ç»Ÿè®¡:\n",
      "        train   val  test\n",
      "call    20034  3000  4992\n",
      "fist    23480  2999  4993\n",
      "like    23197  2999  4992\n",
      "ok      23131  2999  4997\n",
      "one     23034  3000  4995\n",
      "palm    23654  2999  4992\n",
      "rock    22311  2997  4998\n",
      "three   22685  2998  4995\n",
      "two_up  22661  2999  4993\n",
      "\n",
      "æ€»å›¾åƒæ•°é‡: 276124\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_dataset_structure():\n",
    "    \"\"\"åˆ†ææ•°æ®é›†ç»“æ„\"\"\"\n",
    "    base_path = \"/mnt/MCP/hagrid_dataset_512\"\n",
    "    datasets = ['train', 'val', 'test']\n",
    "    classes = ['call', 'fist', 'like', 'ok', 'one', 'palm', 'rock', 'three', 'two_up']\n",
    "    \n",
    "    print(\"ğŸ“Š æ•°æ®é›†ç»“æ„åˆ†æ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    stats = {}\n",
    "    for dataset in datasets:\n",
    "        dataset_stats = {}\n",
    "        dataset_path = os.path.join(base_path, dataset)\n",
    "        \n",
    "        for class_name in classes:\n",
    "            class_path = os.path.join(dataset_path, class_name)\n",
    "            if os.path.exists(class_path):\n",
    "                # ç»Ÿè®¡å›¾åƒæ–‡ä»¶\n",
    "                image_files = [f for f in os.listdir(class_path) \n",
    "                              if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                dataset_stats[class_name] = len(image_files)\n",
    "            else:\n",
    "                dataset_stats[class_name] = 0\n",
    "                print(f\"âš ï¸  è­¦å‘Š: {dataset}/{class_name} ç›®å½•ä¸å­˜åœ¨\")\n",
    "        \n",
    "        stats[dataset] = dataset_stats\n",
    "    \n",
    "    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯\n",
    "    df_stats = pd.DataFrame(stats)\n",
    "    print(\"\\næ•°æ®é›†ç»Ÿè®¡:\")\n",
    "    print(df_stats)\n",
    "    \n",
    "    # æ€»è®¡\n",
    "    total_images = sum(sum(dataset_stats.values()) for dataset_stats in stats.values())\n",
    "    print(f\"\\næ€»å›¾åƒæ•°é‡: {total_images}\")\n",
    "    \n",
    "    return stats, classes\n",
    "\n",
    "# è¿è¡Œåˆ†æ\n",
    "dataset_stats, class_names = analyze_dataset_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8967540a-b932-4e5d-a2f0-66219b2d9138",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ï¸ åˆ›å»ºåˆ†ç±»æ•°æ®é›†ç»“æ„\n",
      "==================================================\n",
      "âœ… åˆ›å»º train ç›®å½•ç»“æ„\n",
      "âœ… åˆ›å»º val ç›®å½•ç»“æ„\n",
      "âœ… åˆ›å»º test ç›®å½•ç»“æ„\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import random\n",
    "\n",
    "def create_classification_dataset():\n",
    "    \"\"\"åˆ›å»ºåˆ†ç±»æ•°æ®é›†æ‰€éœ€çš„æ–‡ä»¶ç»“æ„\"\"\"\n",
    "    base_path = \"/mnt/MCP/hagrid_dataset_512\"\n",
    "    classification_base = \"/mnt/MCP/hagrid_classification\"\n",
    "    \n",
    "    # åˆ›å»ºåˆ†ç±»æ•°æ®é›†ç›®å½•\n",
    "    os.makedirs(classification_base, exist_ok=True)\n",
    "    \n",
    "    datasets = ['train', 'val', 'test']\n",
    "    \n",
    "    print(\"ğŸ—ï¸ åˆ›å»ºåˆ†ç±»æ•°æ®é›†ç»“æ„\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        dataset_path = os.path.join(base_path, dataset)\n",
    "        classification_dataset_path = os.path.join(classification_base, dataset)\n",
    "        \n",
    "        # ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ›å»ºç›®å½•\n",
    "        os.makedirs(classification_dataset_path, exist_ok=True)\n",
    "        \n",
    "        # ä¸ºæ¯ä¸ªç±»åˆ«åˆ›å»ºå­ç›®å½•\n",
    "        for class_name in class_names:\n",
    "            class_path = os.path.join(classification_dataset_path, class_name)\n",
    "            os.makedirs(class_path, exist_ok=True)\n",
    "        \n",
    "        print(f\"âœ… åˆ›å»º {dataset} ç›®å½•ç»“æ„\")\n",
    "    \n",
    "    return classification_base\n",
    "\n",
    "# åˆ›å»ºåˆ†ç±»æ•°æ®é›†ç›®å½•\n",
    "classification_base = create_classification_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d263d4-876d-4cab-8693-a3c93f4b9252",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ·ï¸ ç”Ÿæˆåˆ†ç±»æ ‡ç­¾\n",
      "==================================================\n",
      "ç±»åˆ«æ˜ å°„:\n",
      "  call -> 0\n",
      "  fist -> 1\n",
      "  like -> 2\n",
      "  ok -> 3\n",
      "  one -> 4\n",
      "  palm -> 5\n",
      "  rock -> 6\n",
      "  three -> 7\n",
      "  two_up -> 8\n",
      "âœ… ç±»åˆ«æ˜ å°„å·²ä¿å­˜: /mnt/MCP/hagrid_classification/class_mapping.json\n",
      "  train/call: å¤åˆ¶ 20034 å¼ å›¾åƒ\n",
      "  train/fist: å¤åˆ¶ 23480 å¼ å›¾åƒ\n",
      "  train/like: å¤åˆ¶ 23197 å¼ å›¾åƒ\n",
      "  train/ok: å¤åˆ¶ 23131 å¼ å›¾åƒ\n",
      "  train/one: å¤åˆ¶ 23034 å¼ å›¾åƒ\n",
      "  train/palm: å¤åˆ¶ 23654 å¼ å›¾åƒ\n",
      "  train/rock: å¤åˆ¶ 22311 å¼ å›¾åƒ\n",
      "  train/three: å¤åˆ¶ 22685 å¼ å›¾åƒ\n",
      "  train/two_up: å¤åˆ¶ 22661 å¼ å›¾åƒ\n",
      "âœ… train æ ‡ç­¾æ–‡ä»¶å·²ä¿å­˜: /mnt/MCP/hagrid_classification/train_labels.csv\n",
      "  val/call: å¤åˆ¶ 3000 å¼ å›¾åƒ\n",
      "  val/fist: å¤åˆ¶ 2999 å¼ å›¾åƒ\n",
      "  val/like: å¤åˆ¶ 2999 å¼ å›¾åƒ\n",
      "  val/ok: å¤åˆ¶ 2999 å¼ å›¾åƒ\n",
      "  val/one: å¤åˆ¶ 3000 å¼ å›¾åƒ\n",
      "  val/palm: å¤åˆ¶ 2999 å¼ å›¾åƒ\n",
      "  val/rock: å¤åˆ¶ 2997 å¼ å›¾åƒ\n",
      "  val/three: å¤åˆ¶ 2998 å¼ å›¾åƒ\n",
      "  val/two_up: å¤åˆ¶ 2999 å¼ å›¾åƒ\n",
      "âœ… val æ ‡ç­¾æ–‡ä»¶å·²ä¿å­˜: /mnt/MCP/hagrid_classification/val_labels.csv\n",
      "  test/call: å¤åˆ¶ 4992 å¼ å›¾åƒ\n",
      "  test/fist: å¤åˆ¶ 4993 å¼ å›¾åƒ\n",
      "  test/like: å¤åˆ¶ 4992 å¼ å›¾åƒ\n",
      "  test/ok: å¤åˆ¶ 4997 å¼ å›¾åƒ\n",
      "  test/one: å¤åˆ¶ 4995 å¼ å›¾åƒ\n",
      "  test/palm: å¤åˆ¶ 4992 å¼ å›¾åƒ\n",
      "  test/rock: å¤åˆ¶ 4998 å¼ å›¾åƒ\n",
      "  test/three: å¤åˆ¶ 4995 å¼ å›¾åƒ\n",
      "  test/two_up: å¤åˆ¶ 4993 å¼ å›¾åƒ\n",
      "âœ… test æ ‡ç­¾æ–‡ä»¶å·²ä¿å­˜: /mnt/MCP/hagrid_classification/test_labels.csv\n"
     ]
    }
   ],
   "source": [
    "def create_classification_labels():\n",
    "    \"\"\"åˆ›å»ºåˆ†ç±»æ ‡ç­¾æ–‡ä»¶\"\"\"\n",
    "    base_path = \"/mnt/MCP/hagrid_dataset_512\"\n",
    "    classification_base = \"/mnt/MCP/hagrid_classification\"\n",
    "    \n",
    "    datasets = ['train', 'val', 'test']\n",
    "    \n",
    "    print(\"ğŸ·ï¸ ç”Ÿæˆåˆ†ç±»æ ‡ç­¾\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # åˆ›å»ºç±»åˆ«æ˜ å°„\n",
    "    class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "    idx_to_class = {idx: class_name for class_name, idx in class_to_idx.items()}\n",
    "    \n",
    "    print(\"ç±»åˆ«æ˜ å°„:\")\n",
    "    for class_name, idx in class_to_idx.items():\n",
    "        print(f\"  {class_name} -> {idx}\")\n",
    "    \n",
    "    # ä¿å­˜ç±»åˆ«æ˜ å°„\n",
    "    mapping_file = os.path.join(classification_base, \"class_mapping.json\")\n",
    "    import json\n",
    "    with open(mapping_file, 'w') as f:\n",
    "        json.dump({\n",
    "            'class_to_idx': class_to_idx,\n",
    "            'idx_to_class': idx_to_class\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"âœ… ç±»åˆ«æ˜ å°„å·²ä¿å­˜: {mapping_file}\")\n",
    "    \n",
    "    # ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ›å»ºæ ‡ç­¾æ–‡ä»¶\n",
    "    for dataset in datasets:\n",
    "        dataset_path = os.path.join(base_path, dataset)\n",
    "        classification_dataset_path = os.path.join(classification_base, dataset)\n",
    "        \n",
    "        labels = []\n",
    "        \n",
    "        for class_name in class_names:\n",
    "            class_path = os.path.join(dataset_path, class_name)\n",
    "            if not os.path.exists(class_path):\n",
    "                continue\n",
    "                \n",
    "            # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰å›¾åƒæ–‡ä»¶\n",
    "            image_files = [f for f in os.listdir(class_path) \n",
    "                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            # å¤åˆ¶æ–‡ä»¶åˆ°åˆ†ç±»æ•°æ®é›†ç›®å½•\n",
    "            classification_class_path = os.path.join(classification_dataset_path, class_name)\n",
    "            for image_file in image_files:\n",
    "                src_path = os.path.join(class_path, image_file)\n",
    "                dst_path = os.path.join(classification_class_path, image_file)\n",
    "                \n",
    "                # å¤åˆ¶æ–‡ä»¶\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "                \n",
    "                # è®°å½•æ ‡ç­¾\n",
    "                labels.append({\n",
    "                    'image_path': os.path.join(dataset, class_name, image_file),\n",
    "                    'class_name': class_name,\n",
    "                    'class_idx': class_to_idx[class_name]\n",
    "                })\n",
    "            \n",
    "            print(f\"  {dataset}/{class_name}: å¤åˆ¶ {len(image_files)} å¼ å›¾åƒ\")\n",
    "        \n",
    "        # ä¿å­˜æ ‡ç­¾æ–‡ä»¶\n",
    "        labels_file = os.path.join(classification_base, f\"{dataset}_labels.csv\")\n",
    "        df_labels = pd.DataFrame(labels)\n",
    "        df_labels.to_csv(labels_file, index=False)\n",
    "        print(f\"âœ… {dataset} æ ‡ç­¾æ–‡ä»¶å·²ä¿å­˜: {labels_file}\")\n",
    "    \n",
    "    return classification_base\n",
    "\n",
    "# ç”Ÿæˆåˆ†ç±»æ ‡ç­¾\n",
    "classification_base = create_classification_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "160bd4ee-dbce-4b2d-a7be-feb602ba1b92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” éªŒè¯åˆ†ç±»æ•°æ®é›†\n",
      "==================================================\n",
      "  train/call: 20034 å¼ å›¾åƒ\n",
      "  train/fist: 23480 å¼ å›¾åƒ\n",
      "  train/like: 23197 å¼ å›¾åƒ\n",
      "  train/ok: 23131 å¼ å›¾åƒ\n",
      "  train/one: 23034 å¼ å›¾åƒ\n",
      "  train/palm: 23654 å¼ å›¾åƒ\n",
      "  train/rock: 22311 å¼ å›¾åƒ\n",
      "  train/three: 22685 å¼ å›¾åƒ\n",
      "  train/two_up: 22661 å¼ å›¾åƒ\n",
      "  train æ€»è®¡: 204187 å¼ å›¾åƒ\n",
      "\n",
      "  val/call: 3000 å¼ å›¾åƒ\n",
      "  val/fist: 2999 å¼ å›¾åƒ\n",
      "  val/like: 2999 å¼ å›¾åƒ\n",
      "  val/ok: 2999 å¼ å›¾åƒ\n",
      "  val/one: 3000 å¼ å›¾åƒ\n",
      "  val/palm: 2999 å¼ å›¾åƒ\n",
      "  val/rock: 2997 å¼ å›¾åƒ\n",
      "  val/three: 2998 å¼ å›¾åƒ\n",
      "  val/two_up: 2999 å¼ å›¾åƒ\n",
      "  val æ€»è®¡: 26990 å¼ å›¾åƒ\n",
      "\n",
      "  test/call: 4992 å¼ å›¾åƒ\n",
      "  test/fist: 4993 å¼ å›¾åƒ\n",
      "  test/like: 4992 å¼ å›¾åƒ\n",
      "  test/ok: 4997 å¼ å›¾åƒ\n",
      "  test/one: 4995 å¼ å›¾åƒ\n",
      "  test/palm: 4992 å¼ å›¾åƒ\n",
      "  test/rock: 4998 å¼ å›¾åƒ\n",
      "  test/three: 4995 å¼ å›¾åƒ\n",
      "  test/two_up: 4993 å¼ å›¾åƒ\n",
      "  test æ€»è®¡: 44947 å¼ å›¾åƒ\n",
      "\n",
      "âœ… train æ ‡ç­¾æ–‡ä»¶: 204187 æ¡è®°å½•\n",
      "âœ… val æ ‡ç­¾æ–‡ä»¶: 26990 æ¡è®°å½•\n",
      "âœ… test æ ‡ç­¾æ–‡ä»¶: 44947 æ¡è®°å½•\n"
     ]
    }
   ],
   "source": [
    "def verify_classification_dataset():\n",
    "    \"\"\"éªŒè¯åˆ†ç±»æ•°æ®é›†å®Œæ•´æ€§\"\"\"\n",
    "    classification_base = \"/mnt/MCP/hagrid_classification\"\n",
    "    \n",
    "    print(\"ğŸ” éªŒè¯åˆ†ç±»æ•°æ®é›†\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    datasets = ['train', 'val', 'test']\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        dataset_path = os.path.join(classification_base, dataset)\n",
    "        \n",
    "        if not os.path.exists(dataset_path):\n",
    "            print(f\"âŒ {dataset} ç›®å½•ä¸å­˜åœ¨\")\n",
    "            continue\n",
    "            \n",
    "        total_images = 0\n",
    "        for class_name in class_names:\n",
    "            class_path = os.path.join(dataset_path, class_name)\n",
    "            if os.path.exists(class_path):\n",
    "                image_files = [f for f in os.listdir(class_path) \n",
    "                              if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                total_images += len(image_files)\n",
    "                print(f\"  {dataset}/{class_name}: {len(image_files)} å¼ å›¾åƒ\")\n",
    "            else:\n",
    "                print(f\"  âš ï¸ {dataset}/{class_name}: ç›®å½•ä¸å­˜åœ¨\")\n",
    "        \n",
    "        print(f\"  {dataset} æ€»è®¡: {total_images} å¼ å›¾åƒ\\n\")\n",
    "    \n",
    "    # æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶\n",
    "    for dataset in datasets:\n",
    "        labels_file = os.path.join(classification_base, f\"{dataset}_labels.csv\")\n",
    "        if os.path.exists(labels_file):\n",
    "            df = pd.read_csv(labels_file)\n",
    "            print(f\"âœ… {dataset} æ ‡ç­¾æ–‡ä»¶: {len(df)} æ¡è®°å½•\")\n",
    "        else:\n",
    "            print(f\"âŒ {dataset} æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨\")\n",
    "\n",
    "# éªŒè¯æ•°æ®é›†\n",
    "verify_classification_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d14e827e-d171-474d-9e29-fa73d5ef700b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ åˆ›å»ºåˆ†ç±»æ•°æ®é›†é…ç½®\n",
      "==================================================\n",
      "âœ… æ•°æ®é›†é…ç½®æ–‡ä»¶å·²ä¿å­˜: /mnt/MCP/hagrid_classification/dataset_config.yaml\n",
      "\n",
      "é…ç½®å†…å®¹é¢„è§ˆ:\n",
      "\n",
      "# Hagridæ‰‹åŠ¿åˆ†ç±»æ•°æ®é›†é…ç½®\n",
      "# ç”Ÿæˆæ—¶é—´: 2025-10-18 10:20:36.366129\n",
      "\n",
      "dataset:\n",
      "  name: \"hagrid_gesture_classification\"\n",
      "  path: \"/mnt/MCP/hagrid_classification\"\n",
      "  num_classes: 9\n",
      "  classes: ['call', 'fist', 'like', 'ok', 'one', 'palm', 'rock', 'three', 'two_up']\n",
      "\n",
      "data_paths:\n",
      "  train: \"/mnt/MCP/hagrid_classification/train\"\n",
      "  val: \"/mnt/MCP/hagrid_classification/val\" \n",
      "  test: \"/mnt/MCP/hagrid_classification/test\"\n",
      "\n",
      "label_files:\n",
      "  train: \"/mnt/MCP/hagrid_classification/train_labels.csv\"\n",
      "  val: \"/mnt/MCP/hagrid_classification/val_labels.csv\"\n",
      "  test: \"/mnt/MCP/hagrid_classification/test_labels.csv\"\n",
      "\n",
      "class_mapping:\n",
      "  file: \"/mnt/MCP/hagrid_classification/class_mapping.json\"\n",
      "\n",
      "statistics:\n",
      "  train_images: {'call': 20034, 'fist': 23480, 'like': 23197, 'ok': 23131, 'one': 23034, 'palm': 23654, 'rock': 22311, 'three': 22685, 'two_up': 22661}\n",
      "  val_images: {'call': 3000, 'fist': 2999, 'like': 2999, 'ok': 2999, 'one': 3000, 'palm': 2999, 'rock': 2997, 'three': 2998, 'two_up': 2999}\n",
      "  test_images: {'call': 4992, 'fist': 4993, 'like': 4992, 'ok': 4997, 'one': 4995, 'palm': 4992, 'rock': 4998, 'three': 4995, 'two_up': 4993}\n",
      "  total_images: 276124\n",
      "\n",
      "notes:\n",
      "  - \"æ­¤æ•°æ®é›†ç”¨äº9ç±»æ‰‹åŠ¿åˆ†ç±»ä»»åŠ¡\"\n",
      "  - \"åŸºäºHagridæ•°æ®é›†ç­›é€‰çš„åŒ»ç–—æ‰‹åŠ¿å­é›†\"\n",
      "  - \"å›¾åƒå°ºå¯¸: 512px (ä¿æŒåŸå§‹å°ºå¯¸)\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_classification_config():\n",
    "    \"\"\"åˆ›å»ºåˆ†ç±»æ•°æ®é›†é…ç½®æ–‡ä»¶\"\"\"\n",
    "    classification_base = \"/mnt/MCP/hagrid_classification\"\n",
    "    \n",
    "    print(\"ğŸ“ åˆ›å»ºåˆ†ç±»æ•°æ®é›†é…ç½®\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # åˆ›å»ºé…ç½®æ–‡ä»¶\n",
    "    config_content = f\"\"\"\n",
    "# Hagridæ‰‹åŠ¿åˆ†ç±»æ•°æ®é›†é…ç½®\n",
    "# ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now()}\n",
    "\n",
    "dataset:\n",
    "  name: \"hagrid_gesture_classification\"\n",
    "  path: \"{classification_base}\"\n",
    "  num_classes: {len(class_names)}\n",
    "  classes: {class_names}\n",
    "\n",
    "data_paths:\n",
    "  train: \"{os.path.join(classification_base, 'train')}\"\n",
    "  val: \"{os.path.join(classification_base, 'val')}\" \n",
    "  test: \"{os.path.join(classification_base, 'test')}\"\n",
    "\n",
    "label_files:\n",
    "  train: \"{os.path.join(classification_base, 'train_labels.csv')}\"\n",
    "  val: \"{os.path.join(classification_base, 'val_labels.csv')}\"\n",
    "  test: \"{os.path.join(classification_base, 'test_labels.csv')}\"\n",
    "\n",
    "class_mapping:\n",
    "  file: \"{os.path.join(classification_base, 'class_mapping.json')}\"\n",
    "\n",
    "statistics:\n",
    "  train_images: {dataset_stats['train']}\n",
    "  val_images: {dataset_stats['val']}\n",
    "  test_images: {dataset_stats['test']}\n",
    "  total_images: {sum(sum(dataset_stats[dataset].values()) for dataset in ['train', 'val', 'test'])}\n",
    "\n",
    "notes:\n",
    "  - \"æ­¤æ•°æ®é›†ç”¨äº9ç±»æ‰‹åŠ¿åˆ†ç±»ä»»åŠ¡\"\n",
    "  - \"åŸºäºHagridæ•°æ®é›†ç­›é€‰çš„åŒ»ç–—æ‰‹åŠ¿å­é›†\"\n",
    "  - \"å›¾åƒå°ºå¯¸: 512px (ä¿æŒåŸå§‹å°ºå¯¸)\"\n",
    "\"\"\"\n",
    "    \n",
    "    config_file = os.path.join(classification_base, \"dataset_config.yaml\")\n",
    "    with open(config_file, 'w') as f:\n",
    "        f.write(config_content)\n",
    "    \n",
    "    print(f\"âœ… æ•°æ®é›†é…ç½®æ–‡ä»¶å·²ä¿å­˜: {config_file}\")\n",
    "    print(\"\\né…ç½®å†…å®¹é¢„è§ˆ:\")\n",
    "    print(config_content)\n",
    "\n",
    "# åˆ›å»ºé…ç½®æ–‡ä»¶\n",
    "create_classification_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54f53ca-888f-42c2-a4d3-e8847c75355a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª æµ‹è¯•æ•°æ®åŠ è½½å™¨\n",
      "==================================================\n",
      "âœ… æˆåŠŸåŠ è½½è®­ç»ƒæ•°æ®é›†\n",
      "   ç±»åˆ«æ•°é‡: 9\n",
      "   ç±»åˆ«åç§°: ['call', 'fist', 'like', 'ok', 'one', 'palm', 'rock', 'three', 'two_up']\n",
      "   æ ·æœ¬æ•°é‡: 204187\n",
      "   æ ·æœ¬å›¾åƒå½¢çŠ¶: torch.Size([3, 224, 224])\n",
      "   æ ·æœ¬æ ‡ç­¾: 0 (call)\n"
     ]
    }
   ],
   "source": [
    "def test_data_loader():\n",
    "    \"\"\"æµ‹è¯•æ•°æ®åŠ è½½å™¨\"\"\"\n",
    "    print(\"ğŸ§ª æµ‹è¯•æ•°æ®åŠ è½½å™¨\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    classification_base = \"/mnt/MCP/hagrid_classification\"\n",
    "    train_path = os.path.join(classification_base, \"train\")\n",
    "    \n",
    "    # ä½¿ç”¨PyTorchçš„ImageFolderæµ‹è¯•æ•°æ®åŠ è½½\n",
    "    try:\n",
    "        from torchvision import datasets, transforms\n",
    "        \n",
    "        # ç®€å•çš„æ•°æ®è½¬æ¢\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "        # åˆ›å»ºæ•°æ®é›†\n",
    "        train_dataset = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "        \n",
    "        print(f\"âœ… æˆåŠŸåŠ è½½è®­ç»ƒæ•°æ®é›†\")\n",
    "        print(f\"   ç±»åˆ«æ•°é‡: {len(train_dataset.classes)}\")\n",
    "        print(f\"   ç±»åˆ«åç§°: {train_dataset.classes}\")\n",
    "        print(f\"   æ ·æœ¬æ•°é‡: {len(train_dataset)}\")\n",
    "        \n",
    "        # æ˜¾ç¤ºä¸€ä¸ªæ ·æœ¬\n",
    "        sample_image, sample_label = train_dataset[0]\n",
    "        print(f\"   æ ·æœ¬å›¾åƒå½¢çŠ¶: {sample_image.shape}\")\n",
    "        print(f\"   æ ·æœ¬æ ‡ç­¾: {sample_label} ({train_dataset.classes[sample_label]})\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"âŒ æœªå®‰è£…torchvisionï¼Œæ— æ³•æµ‹è¯•æ•°æ®åŠ è½½å™¨\")\n",
    "        print(\"   è¯·è¿è¡Œ: pip install torchvision\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ•°æ®åŠ è½½å™¨æµ‹è¯•å¤±è´¥: {e}\")\n",
    "\n",
    "# æµ‹è¯•æ•°æ®åŠ è½½å™¨\n",
    "test_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "024cb134-c907-43f7-ae5a-024c688ccc8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ åˆ†ç±»æ•°æ®å‡†å¤‡çŠ¶æ€æ£€æŸ¥\n",
      "==================================================\n",
      "âœ… train\n",
      "âœ… val\n",
      "âœ… test\n",
      "âœ… train_labels.csv\n",
      "âœ… val_labels.csv\n",
      "âœ… test_labels.csv\n",
      "âœ… class_mapping.json\n",
      "âœ… dataset_config.yaml\n",
      "\n",
      "ğŸ‰ åˆ†ç±»æ•°æ®å‡†å¤‡å®Œæˆï¼\n",
      "ä¸‹ä¸€æ­¥: å¼€å§‹è®­ç»ƒåˆ†ç±»æ¨¡å‹\n"
     ]
    }
   ],
   "source": [
    "def check_classification_preparation_status():\n",
    "    \"\"\"æ£€æŸ¥åˆ†ç±»æ•°æ®å‡†å¤‡çŠ¶æ€\"\"\"\n",
    "    classification_base = \"/mnt/MCP/hagrid_classification\"\n",
    "    \n",
    "    print(\"ğŸ¯ åˆ†ç±»æ•°æ®å‡†å¤‡çŠ¶æ€æ£€æŸ¥\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    required_files = [\n",
    "        \"train\", \"val\", \"test\",\n",
    "        \"train_labels.csv\", \"val_labels.csv\", \"test_labels.csv\", \n",
    "        \"class_mapping.json\", \"dataset_config.yaml\"\n",
    "    ]\n",
    "    \n",
    "    all_good = True\n",
    "    for item in required_files:\n",
    "        item_path = os.path.join(classification_base, item)\n",
    "        exists = os.path.exists(item_path)\n",
    "        status = \"âœ…\" if exists else \"âŒ\"\n",
    "        print(f\"{status} {item}\")\n",
    "        \n",
    "        if not exists:\n",
    "            all_good = False\n",
    "    \n",
    "    if all_good:\n",
    "        print(\"\\nğŸ‰ åˆ†ç±»æ•°æ®å‡†å¤‡å®Œæˆï¼\")\n",
    "        print(\"ä¸‹ä¸€æ­¥: å¼€å§‹è®­ç»ƒåˆ†ç±»æ¨¡å‹\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  åˆ†ç±»æ•°æ®å‡†å¤‡æœªå®Œæˆï¼Œè¯·æ£€æŸ¥ç¼ºå¤±çš„æ–‡ä»¶\")\n",
    "\n",
    "# æ£€æŸ¥çŠ¶æ€\n",
    "check_classification_preparation_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2efb98c-317a-4cf8-beae-bdaf2530453c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¯é‡å¤æ€§\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6bb813a-3974-4074-a4f7-9cce23e6fc44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ•°æ®è½¬æ¢è®¾ç½®å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "def setup_data_transforms():\n",
    "    \"\"\"è®¾ç½®æ•°æ®é¢„å¤„ç†å’Œå¢å¼ºè½¬æ¢\"\"\"\n",
    "    \n",
    "    # è®­ç»ƒæ•°æ®è½¬æ¢ï¼ˆåŒ…å«æ•°æ®å¢å¼ºï¼‰\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  # è°ƒæ•´å¤§å°\n",
    "        transforms.RandomCrop(224),     # éšæœºè£å‰ª\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # éšæœºæ°´å¹³ç¿»è½¬\n",
    "        transforms.RandomRotation(10),  # éšæœºæ—‹è½¬\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # é¢œè‰²æŠ–åŠ¨\n",
    "        transforms.ToTensor(),          # è½¬æ¢ä¸ºå¼ é‡\n",
    "        transforms.Normalize(           # æ ‡å‡†åŒ–\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # éªŒè¯å’Œæµ‹è¯•æ•°æ®è½¬æ¢ï¼ˆä¸åŒ…å«æ•°æ®å¢å¼ºï¼‰\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),     # ä¸­å¿ƒè£å‰ª\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "# è®¾ç½®æ•°æ®è½¬æ¢\n",
    "train_transform, val_transform = setup_data_transforms()\n",
    "print(\"âœ… æ•°æ®è½¬æ¢è®¾ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "046a4bbb-a89c-4f63-aa38-63e001ea8304",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ\n",
      "   è®­ç»ƒé›†: 204187 å¼ å›¾åƒ\n",
      "   éªŒè¯é›†: 26990 å¼ å›¾åƒ\n",
      "   æµ‹è¯•é›†: 44947 å¼ å›¾åƒ\n",
      "   ç±»åˆ«æ•°: 9\n",
      "   ç±»åˆ«åç§°: ['call', 'fist', 'like', 'ok', 'one', 'palm', 'rock', 'three', 'two_up']\n"
     ]
    }
   ],
   "source": [
    "def create_data_loaders(batch_size=32):\n",
    "    \"\"\"åˆ›å»ºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®åŠ è½½å™¨\"\"\"\n",
    "    \n",
    "    classification_base = \"/mnt/MCP/hagrid_classification\"\n",
    "    \n",
    "    # åˆ›å»ºæ•°æ®é›†\n",
    "    train_dataset = ImageFolder(\n",
    "        root=os.path.join(classification_base, 'train'),\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageFolder(\n",
    "        root=os.path.join(classification_base, 'val'),\n",
    "        transform=val_transform\n",
    "    )\n",
    "    \n",
    "    test_dataset = ImageFolder(\n",
    "        root=os.path.join(classification_base, 'test'),\n",
    "        transform=val_transform\n",
    "    )\n",
    "    \n",
    "    # åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # è·å–ç±»åˆ«ä¿¡æ¯\n",
    "    class_names = train_dataset.classes\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    print(f\"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ\")\n",
    "    print(f\"   è®­ç»ƒé›†: {len(train_dataset)} å¼ å›¾åƒ\")\n",
    "    print(f\"   éªŒè¯é›†: {len(val_dataset)} å¼ å›¾åƒ\") \n",
    "    print(f\"   æµ‹è¯•é›†: {len(test_dataset)} å¼ å›¾åƒ\")\n",
    "    print(f\"   ç±»åˆ«æ•°: {num_classes}\")\n",
    "    print(f\"   ç±»åˆ«åç§°: {class_names}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, class_names, num_classes\n",
    "\n",
    "# åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "train_loader, val_loader, test_loader, class_names, num_classes = create_data_loaders(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d06b5be3-3fd5-4af8-bf8f-467d6c196ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:07<00:00, 6.04MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ResNet18æ¨¡å‹åˆ›å»ºå®Œæˆ\n",
      "   ä½¿ç”¨é¢„è®­ç»ƒæƒé‡: True\n",
      "   è¾“å‡ºç±»åˆ«æ•°: 9\n",
      "   æœ€ç»ˆå…¨è¿æ¥å±‚: 512 -> 9\n",
      "âœ… æ¨¡å‹å·²ç§»åŠ¨åˆ°: cuda\n"
     ]
    }
   ],
   "source": [
    "def create_resnet18_model(num_classes, use_pretrained=True):\n",
    "    \"\"\"åˆ›å»ºå¹¶é…ç½®ResNet18æ¨¡å‹\"\"\"\n",
    "    \n",
    "    # åŠ è½½é¢„è®­ç»ƒçš„ResNet18æ¨¡å‹\n",
    "    model = models.resnet18(pretrained=use_pretrained)\n",
    "    \n",
    "    # å†»ç»“å‰é¢çš„å±‚ï¼ˆå¯é€‰ï¼Œç”¨äºè¿ç§»å­¦ä¹ ï¼‰\n",
    "    # for param in model.parameters():\n",
    "    #     param.requires_grad = False\n",
    "    \n",
    "    # ä¿®æ”¹æœ€åçš„å…¨è¿æ¥å±‚ä»¥é€‚åº”æˆ‘ä»¬çš„ç±»åˆ«æ•°\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    # æ‰“å°æ¨¡å‹ä¿¡æ¯\n",
    "    print(f\"âœ… ResNet18æ¨¡å‹åˆ›å»ºå®Œæˆ\")\n",
    "    print(f\"   ä½¿ç”¨é¢„è®­ç»ƒæƒé‡: {use_pretrained}\")\n",
    "    print(f\"   è¾“å‡ºç±»åˆ«æ•°: {num_classes}\")\n",
    "    print(f\"   æœ€ç»ˆå…¨è¿æ¥å±‚: {num_features} -> {num_classes}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "model = create_resnet18_model(num_classes=num_classes, use_pretrained=True)\n",
    "\n",
    "# å¦‚æœæœ‰GPUï¼Œå°†æ¨¡å‹ç§»åˆ°GPUä¸Š\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"âœ… æ¨¡å‹å·²ç§»åŠ¨åˆ°: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f3994e1-c5f7-4891-a8d8-ada29d507e7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è®­ç»ƒå‚æ•°è®¾ç½®å®Œæˆ\n",
      "   æŸå¤±å‡½æ•°: CrossEntropyLoss\n",
      "   ä¼˜åŒ–å™¨: Adam (lr=0.001)\n",
      "   å­¦ä¹ ç‡è°ƒåº¦å™¨: StepLR (step_size=7, gamma=0.1)\n",
      "   è®­ç»ƒè½®æ•°: 25\n"
     ]
    }
   ],
   "source": [
    "def setup_training_parameters(model):\n",
    "    \"\"\"è®¾ç½®è®­ç»ƒå‚æ•°ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\"\"\"\n",
    "    \n",
    "    # æŸå¤±å‡½æ•°\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # ä¼˜åŒ–å™¨\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    \n",
    "    # å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    \n",
    "    # è®­ç»ƒå‚æ•°\n",
    "    num_epochs = 25\n",
    "    \n",
    "    print(\"âœ… è®­ç»ƒå‚æ•°è®¾ç½®å®Œæˆ\")\n",
    "    print(f\"   æŸå¤±å‡½æ•°: CrossEntropyLoss\")\n",
    "    print(f\"   ä¼˜åŒ–å™¨: Adam (lr=0.001)\")\n",
    "    print(f\"   å­¦ä¹ ç‡è°ƒåº¦å™¨: StepLR (step_size=7, gamma=0.1)\")\n",
    "    print(f\"   è®­ç»ƒè½®æ•°: {num_epochs}\")\n",
    "    \n",
    "    return criterion, optimizer, scheduler, num_epochs\n",
    "\n",
    "# è®¾ç½®è®­ç»ƒå‚æ•°\n",
    "criterion, optimizer, scheduler, num_epochs = setup_training_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af31ef21-ab19-4ab6-a47a-e3e9d0b9f968",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è®­ç»ƒå†å²è®°å½•è®¾ç½®å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "def setup_training_history():\n",
    "    \"\"\"è®¾ç½®è®­ç»ƒå†å²è®°å½•\"\"\"\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'learning_rates': []\n",
    "    }\n",
    "    return history\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"ç»˜åˆ¶è®­ç»ƒå†å²å›¾è¡¨\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # ç»˜åˆ¶æŸå¤±æ›²çº¿\n",
    "    ax1.plot(history['train_loss'], label='è®­ç»ƒæŸå¤±')\n",
    "    ax1.plot(history['val_loss'], label='éªŒè¯æŸå¤±')\n",
    "    ax1.set_title('æ¨¡å‹æŸå¤±')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿\n",
    "    ax2.plot(history['train_acc'], label='è®­ç»ƒå‡†ç¡®ç‡')\n",
    "    ax2.plot(history['val_acc'], label='éªŒè¯å‡†ç¡®ç‡')\n",
    "    ax2.set_title('æ¨¡å‹å‡†ç¡®ç‡')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# è®¾ç½®è®­ç»ƒå†å²è®°å½•\n",
    "history = setup_training_history()\n",
    "print(\"âœ… è®­ç»ƒå†å²è®°å½•è®¾ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "559cc5eb-22aa-478c-8e21-5d213c4770e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¨¡å‹ç›®å½•åˆ›å»ºå®Œæˆ: /mnt/MCP/gesture_models\n"
     ]
    }
   ],
   "source": [
    "def create_model_directories():\n",
    "    \"\"\"åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•\"\"\"\n",
    "    model_dir = \"/mnt/MCP/gesture_models\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    checkpoint_dir = os.path.join(model_dir, \"checkpoints\")\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"âœ… æ¨¡å‹ç›®å½•åˆ›å»ºå®Œæˆ: {model_dir}\")\n",
    "    return model_dir, checkpoint_dir\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹ç›®å½•\n",
    "model_dir, checkpoint_dir = create_model_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9db97fa7-a866-46e0-85f6-ade9df824b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è®­ç»ƒé…ç½®å·²ä¿å­˜: /mnt/MCP/gesture_models/training_config.json\n"
     ]
    }
   ],
   "source": [
    "def save_training_config(model_dir, class_names, num_classes, training_params):\n",
    "    \"\"\"ä¿å­˜è®­ç»ƒé…ç½®\"\"\"\n",
    "    config = {\n",
    "        'class_names': class_names,\n",
    "        'num_classes': num_classes,\n",
    "        'model_architecture': 'ResNet18',\n",
    "        'training_params': training_params,\n",
    "        'input_size': [3, 224, 224],\n",
    "        'normalization': {\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config_file = os.path.join(model_dir, \"training_config.json\")\n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(f\"âœ… è®­ç»ƒé…ç½®å·²ä¿å­˜: {config_file}\")\n",
    "\n",
    "# ä¿å­˜è®­ç»ƒé…ç½®\n",
    "training_params = {\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': num_epochs,\n",
    "    'optimizer': 'Adam',\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    'scheduler': 'StepLR(step_size=7, gamma=0.1)'\n",
    "}\n",
    "\n",
    "save_training_config(model_dir, class_names, num_classes, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d74a1da6-b0e1-4b50-9209-0f821539caaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ è®­ç»ƒå‡†å¤‡çŠ¶æ€æ£€æŸ¥\n",
      "==================================================\n",
      "âœ… æ•°æ®è½¬æ¢\n",
      "âœ… æ•°æ®åŠ è½½å™¨\n",
      "âœ… æ¨¡å‹åˆ›å»º\n",
      "âœ… è®­ç»ƒè®¾å¤‡\n",
      "âœ… æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
      "âœ… è®­ç»ƒå‡½æ•°\n",
      "âœ… å†å²è®°å½•\n",
      "âœ… æ¨¡å‹ç›®å½•\n",
      "âœ… è®­ç»ƒé…ç½®\n",
      "\n",
      "ğŸ‰ è®­ç»ƒå‡†å¤‡å®Œæˆï¼\n",
      "ä¸‹ä¸€æ­¥: å¼€å§‹æ¨¡å‹è®­ç»ƒ\n",
      "å°†è®­ç»ƒ 25 ä¸ªepochï¼Œä½¿ç”¨ cuda\n"
     ]
    }
   ],
   "source": [
    "def check_training_preparation_status():\n",
    "    \"\"\"æ£€æŸ¥è®­ç»ƒå‡†å¤‡çŠ¶æ€\"\"\"\n",
    "    print(\"ğŸ¯ è®­ç»ƒå‡†å¤‡çŠ¶æ€æ£€æŸ¥\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    checks = [\n",
    "        (\"æ•°æ®è½¬æ¢\", True),\n",
    "        (\"æ•°æ®åŠ è½½å™¨\", True),\n",
    "        (\"æ¨¡å‹åˆ›å»º\", True),\n",
    "        (\"è®­ç»ƒè®¾å¤‡\", True),\n",
    "        (\"æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\", True),\n",
    "        (\"è®­ç»ƒå‡½æ•°\", True),\n",
    "        (\"å†å²è®°å½•\", True),\n",
    "        (\"æ¨¡å‹ç›®å½•\", True),\n",
    "        (\"è®­ç»ƒé…ç½®\", True)\n",
    "    ]\n",
    "    \n",
    "    all_good = True\n",
    "    for check_name, status in checks:\n",
    "        symbol = \"âœ…\" if status else \"âŒ\"\n",
    "        print(f\"{symbol} {check_name}\")\n",
    "        if not status:\n",
    "            all_good = False\n",
    "    \n",
    "    if all_good:\n",
    "        print(\"\\nğŸ‰ è®­ç»ƒå‡†å¤‡å®Œæˆï¼\")\n",
    "        print(\"ä¸‹ä¸€æ­¥: å¼€å§‹æ¨¡å‹è®­ç»ƒ\")\n",
    "        print(f\"å°†è®­ç»ƒ {num_epochs} ä¸ªepochï¼Œä½¿ç”¨ {device}\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ è®­ç»ƒå‡†å¤‡æœªå®Œæˆï¼Œè¯·æ£€æŸ¥é—®é¢˜\")\n",
    "\n",
    "# æ£€æŸ¥çŠ¶æ€\n",
    "check_training_preparation_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e578270a-a217-4da4-b954-88e1b00a1b86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è®­ç»ƒå’ŒéªŒè¯å‡½æ•°å·²é‡æ–°å®šä¹‰\n"
     ]
    }
   ],
   "source": [
    "# é‡æ–°å®šä¹‰è®­ç»ƒå’ŒéªŒè¯å‡½æ•°\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"è®­ç»ƒä¸€ä¸ªepoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"è®­ç»ƒ\")\n",
    "    for inputs, labels in pbar:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # å‰å‘ä¼ æ’­\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # åå‘ä¼ æ’­\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # ç»Ÿè®¡\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        # æ›´æ–°è¿›åº¦æ¡\n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{torch.sum(preds == labels.data).item() / len(labels):.4f}'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"éªŒè¯ä¸€ä¸ªepoch\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=\"éªŒè¯\")\n",
    "        for inputs, labels in pbar:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{torch.sum(preds == labels.data).item() / len(labels):.4f}'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "print(\"âœ… è®­ç»ƒå’ŒéªŒè¯å‡½æ•°å·²é‡æ–°å®šä¹‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7054a8-5b29-47df-8372-277ef3e51851",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ é‡æ–°å¼€å§‹æ¨¡å‹è®­ç»ƒ\n",
      "============================================================\n",
      "\n",
      "Epoch 1/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [25:48<00:00,  4.12it/s, Loss=0.3057, Acc=0.9259]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [01:16<00:00, 11.06it/s, Loss=0.1073, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.4913, è®­ç»ƒå‡†ç¡®ç‡: 0.8382\n",
      "éªŒè¯æŸå¤±: 0.2798, éªŒè¯å‡†ç¡®ç‡: 0.9127\n",
      "å­¦ä¹ ç‡: 0.001000\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_1.pth (å‡†ç¡®ç‡: 0.9127)\n",
      "\n",
      "Epoch 2/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [12:34<00:00,  8.46it/s, Loss=0.2840, Acc=0.8889]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.07it/s, Loss=0.1654, Acc=0.9286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.2960, è®­ç»ƒå‡†ç¡®ç‡: 0.9049\n",
      "éªŒè¯æŸå¤±: 0.2421, éªŒè¯å‡†ç¡®ç‡: 0.9225\n",
      "å­¦ä¹ ç‡: 0.001000\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_2.pth (å‡†ç¡®ç‡: 0.9225)\n",
      "\n",
      "Epoch 3/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:43<00:00,  9.92it/s, Loss=0.2919, Acc=0.8889]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.18it/s, Loss=0.0721, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.2549, è®­ç»ƒå‡†ç¡®ç‡: 0.9189\n",
      "éªŒè¯æŸå¤±: 0.2014, éªŒè¯å‡†ç¡®ç‡: 0.9343\n",
      "å­¦ä¹ ç‡: 0.001000\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_3.pth (å‡†ç¡®ç‡: 0.9343)\n",
      "\n",
      "Epoch 4/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:52<00:00,  9.78it/s, Loss=0.5200, Acc=0.8148]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:50<00:00, 16.68it/s, Loss=0.1123, Acc=0.9286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.2384, è®­ç»ƒå‡†ç¡®ç‡: 0.9236\n",
      "éªŒè¯æŸå¤±: 0.1821, éªŒè¯å‡†ç¡®ç‡: 0.9417\n",
      "å­¦ä¹ ç‡: 0.001000\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_4.pth (å‡†ç¡®ç‡: 0.9417)\n",
      "\n",
      "Epoch 5/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [11:03<00:00,  9.62it/s, Loss=0.0601, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.19it/s, Loss=0.2674, Acc=0.9286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.2250, è®­ç»ƒå‡†ç¡®ç‡: 0.9282\n",
      "éªŒè¯æŸå¤±: 0.2043, éªŒè¯å‡†ç¡®ç‡: 0.9338\n",
      "å­¦ä¹ ç‡: 0.001000\n",
      "ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: /mnt/MCP/gesture_models/checkpoints/checkpoint_epoch_5.pth\n",
      "\n",
      "Epoch 6/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:42<00:00,  9.94it/s, Loss=0.3926, Acc=0.8519]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:47<00:00, 17.58it/s, Loss=0.0637, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.2188, è®­ç»ƒå‡†ç¡®ç‡: 0.9299\n",
      "éªŒè¯æŸå¤±: 0.2048, éªŒè¯å‡†ç¡®ç‡: 0.9330\n",
      "å­¦ä¹ ç‡: 0.001000\n",
      "\n",
      "Epoch 7/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:43<00:00,  9.91it/s, Loss=0.1167, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.15it/s, Loss=0.1444, Acc=0.9286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.2123, è®­ç»ƒå‡†ç¡®ç‡: 0.9317\n",
      "éªŒè¯æŸå¤±: 0.1661, éªŒè¯å‡†ç¡®ç‡: 0.9466\n",
      "å­¦ä¹ ç‡: 0.001000\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_7.pth (å‡†ç¡®ç‡: 0.9466)\n",
      "\n",
      "Epoch 8/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:44<00:00,  9.91it/s, Loss=0.0923, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.54it/s, Loss=0.0208, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.1233, è®­ç»ƒå‡†ç¡®ç‡: 0.9599\n",
      "éªŒè¯æŸå¤±: 0.0841, éªŒè¯å‡†ç¡®ç‡: 0.9723\n",
      "å­¦ä¹ ç‡: 0.000100\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_8.pth (å‡†ç¡®ç‡: 0.9723)\n",
      "\n",
      "Epoch 9/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:53<00:00,  9.77it/s, Loss=0.1168, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.32it/s, Loss=0.0152, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.1030, è®­ç»ƒå‡†ç¡®ç‡: 0.9661\n",
      "éªŒè¯æŸå¤±: 0.0758, éªŒè¯å‡†ç¡®ç‡: 0.9764\n",
      "å­¦ä¹ ç‡: 0.000100\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_9.pth (å‡†ç¡®ç‡: 0.9764)\n",
      "\n",
      "Epoch 10/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:51<00:00,  9.80it/s, Loss=0.0364, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.22it/s, Loss=0.0083, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0948, è®­ç»ƒå‡†ç¡®ç‡: 0.9689\n",
      "éªŒè¯æŸå¤±: 0.0724, éªŒè¯å‡†ç¡®ç‡: 0.9760\n",
      "å­¦ä¹ ç‡: 0.000100\n",
      "ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: /mnt/MCP/gesture_models/checkpoints/checkpoint_epoch_10.pth\n",
      "\n",
      "Epoch 11/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:50<00:00,  9.81it/s, Loss=0.2900, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.34it/s, Loss=0.0055, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0890, è®­ç»ƒå‡†ç¡®ç‡: 0.9705\n",
      "éªŒè¯æŸå¤±: 0.0729, éªŒè¯å‡†ç¡®ç‡: 0.9759\n",
      "å­¦ä¹ ç‡: 0.000100\n",
      "\n",
      "Epoch 12/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:43<00:00,  9.91it/s, Loss=0.0353, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.38it/s, Loss=0.0096, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0850, è®­ç»ƒå‡†ç¡®ç‡: 0.9721\n",
      "éªŒè¯æŸå¤±: 0.0679, éªŒè¯å‡†ç¡®ç‡: 0.9777\n",
      "å­¦ä¹ ç‡: 0.000100\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_12.pth (å‡†ç¡®ç‡: 0.9777)\n",
      "\n",
      "Epoch 13/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:48<00:00,  9.85it/s, Loss=0.0219, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.17it/s, Loss=0.0361, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0822, è®­ç»ƒå‡†ç¡®ç‡: 0.9727\n",
      "éªŒè¯æŸå¤±: 0.0676, éªŒè¯å‡†ç¡®ç‡: 0.9775\n",
      "å­¦ä¹ ç‡: 0.000100\n",
      "\n",
      "Epoch 14/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:39<00:00,  9.97it/s, Loss=0.0047, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.32it/s, Loss=0.0032, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0785, è®­ç»ƒå‡†ç¡®ç‡: 0.9743\n",
      "éªŒè¯æŸå¤±: 0.0622, éªŒè¯å‡†ç¡®ç‡: 0.9787\n",
      "å­¦ä¹ ç‡: 0.000100\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_14.pth (å‡†ç¡®ç‡: 0.9787)\n",
      "\n",
      "Epoch 15/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:50<00:00,  9.81it/s, Loss=0.0052, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:47<00:00, 17.59it/s, Loss=0.0038, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0707, è®­ç»ƒå‡†ç¡®ç‡: 0.9767\n",
      "éªŒè¯æŸå¤±: 0.0590, éªŒè¯å‡†ç¡®ç‡: 0.9805\n",
      "å­¦ä¹ ç‡: 0.000010\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_15.pth (å‡†ç¡®ç‡: 0.9805)\n",
      "ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: /mnt/MCP/gesture_models/checkpoints/checkpoint_epoch_15.pth\n",
      "\n",
      "Epoch 16/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:48<00:00,  9.84it/s, Loss=0.1593, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.11it/s, Loss=0.0025, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0657, è®­ç»ƒå‡†ç¡®ç‡: 0.9780\n",
      "éªŒè¯æŸå¤±: 0.0582, éªŒè¯å‡†ç¡®ç‡: 0.9804\n",
      "å­¦ä¹ ç‡: 0.000010\n",
      "\n",
      "Epoch 17/25\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 6170/6381 [10:29<00:21,  9.92it/s, Loss=0.1351, Acc=0.9375]"
     ]
    }
   ],
   "source": [
    "# é‡æ–°å¼€å§‹è®­ç»ƒ\n",
    "print(\"ğŸš€ é‡æ–°å¼€å§‹æ¨¡å‹è®­ç»ƒ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# åˆå§‹åŒ–æœ€ä½³å‡†ç¡®ç‡\n",
    "best_val_acc = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "# è®­ç»ƒå†å²è®°å½•\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # è®­ç»ƒä¸€ä¸ªepoch\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # éªŒè¯ä¸€ä¸ªepoch\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # æ›´æ–°å­¦ä¹ ç‡\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step()\n",
    "    \n",
    "    # è®°å½•å†å²\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc.cpu().numpy())\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc.cpu().numpy())\n",
    "    history['learning_rates'].append(current_lr)\n",
    "    \n",
    "    print(f\"è®­ç»ƒæŸå¤±: {train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}\")\n",
    "    print(f\"éªŒè¯æŸå¤±: {val_loss:.4f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}\")\n",
    "    print(f\"å­¦ä¹ ç‡: {current_lr:.6f}\")\n",
    "    \n",
    "    # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch + 1\n",
    "        \n",
    "        # ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'train_loss': train_loss\n",
    "        }\n",
    "        \n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'best_model_epoch_{epoch+1}.pth')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: {checkpoint_path} (å‡†ç¡®ç‡: {val_acc:.4f})\")\n",
    "    \n",
    "    # æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡å¸¸è§„æ£€æŸ¥ç‚¹\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ è®­ç»ƒå®Œæˆ!\")\n",
    "print(f\"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f} (ç¬¬ {best_epoch} ä¸ªepoch)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5640b27a-f84f-4ae3-9ecd-8c9ed3448767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ é‡æ–°é…ç½®è®­ç»ƒå‚æ•°ä»¥è®­ç»ƒ100ä¸ªepochå¹¶é˜²æ­¢è¿‡æ‹Ÿåˆ\n",
      "============================================================\n",
      "âœ… è®­ç»ƒå‚æ•°å·²é‡æ–°é…ç½®:\n",
      "   æ€»è®­ç»ƒè½®æ•°: 100\n",
      "   ä¼˜åŒ–å™¨: Adam (lr=0.001, weight_decay=1e-3)\n",
      "   å­¦ä¹ ç‡è°ƒåº¦å™¨: CosineAnnealingLR\n",
      "   æ—©åœæœºåˆ¶: patience=15, min_delta=0.001\n"
     ]
    }
   ],
   "source": [
    "# ä¿®æ”¹è®­ç»ƒé…ç½®ä»¥è®­ç»ƒ100ä¸ªepochå¹¶é˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "print(\"ğŸ”„ é‡æ–°é…ç½®è®­ç»ƒå‚æ•°ä»¥è®­ç»ƒ100ä¸ªepochå¹¶é˜²æ­¢è¿‡æ‹Ÿåˆ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# é‡æ–°è®¾ç½®è®­ç»ƒå‚æ•°\n",
    "num_epochs = 100\n",
    "\n",
    "# é‡æ–°åˆå§‹åŒ–ä¼˜åŒ–å™¨ï¼ŒåŠ å…¥æ›´å¼ºçš„æƒé‡è¡°å‡\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-3)  # å¢åŠ æƒé‡è¡°å‡\n",
    "\n",
    "# ä½¿ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œæ›´é€‚åˆé•¿è®­ç»ƒ\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
    "\n",
    "# æ·»åŠ æ—©åœæœºåˆ¶\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.001, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_val_acc = 0\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.best_model_state = None\n",
    "        \n",
    "    def __call__(self, val_acc, epoch, model):\n",
    "        if val_acc > self.best_val_acc + self.min_delta:\n",
    "            self.best_val_acc = val_acc\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0\n",
    "            if self.restore_best_weights:\n",
    "                self.best_model_state = model.state_dict().copy()\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"ğŸš¨ æ—©åœè§¦å‘! åœ¨ {epoch} ä¸ªepochååœæ­¢è®­ç»ƒ\")\n",
    "                if self.restore_best_weights and self.best_model_state is not None:\n",
    "                    model.load_state_dict(self.best_model_state)\n",
    "                    print(f\"âœ… å·²æ¢å¤ç¬¬ {self.best_epoch} ä¸ªepochçš„æœ€ä½³æ¨¡å‹\")\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "# åˆ›å»ºæ—©åœå®ä¾‹\n",
    "early_stopping = EarlyStopping(patience=15, min_delta=0.001)\n",
    "\n",
    "print(\"âœ… è®­ç»ƒå‚æ•°å·²é‡æ–°é…ç½®:\")\n",
    "print(f\"   æ€»è®­ç»ƒè½®æ•°: {num_epochs}\")\n",
    "print(f\"   ä¼˜åŒ–å™¨: Adam (lr=0.001, weight_decay=1e-3)\")\n",
    "print(f\"   å­¦ä¹ ç‡è°ƒåº¦å™¨: CosineAnnealingLR\")\n",
    "print(f\"   æ—©åœæœºåˆ¶: patience=15, min_delta=0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a22085e-84d5-431e-8076-492f60a5e822",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ\n",
      "==================================================\n",
      "ğŸ“ åŠ è½½æ£€æŸ¥ç‚¹: best_model_epoch_9.pth\n",
      "âœ… ä»ç¬¬ 9 ä¸ªepochç»§ç»­è®­ç»ƒ\n",
      "   å½“å‰æœ€ä½³éªŒè¯å‡†ç¡®ç‡: 0.9764\n",
      "\n",
      "ğŸš€ ç»§ç»­è®­ç»ƒåˆ° 100 ä¸ªepoch\n",
      "============================================================\n",
      "\n",
      "Epoch 10/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:49<00:00,  9.83it/s, Loss=0.0042, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:47<00:00, 17.63it/s, Loss=0.0120, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0948, è®­ç»ƒå‡†ç¡®ç‡: 0.9689\n",
      "éªŒè¯æŸå¤±: 0.0732, éªŒè¯å‡†ç¡®ç‡: 0.9763\n",
      "å­¦ä¹ ç‡: 0.000100\n",
      "ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: /mnt/MCP/gesture_models/checkpoints/checkpoint_epoch_10.pth\n",
      "\n",
      "Epoch 11/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:50<00:00,  9.81it/s, Loss=0.2489, Acc=0.9259]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.15it/s, Loss=0.0143, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0880, è®­ç»ƒå‡†ç¡®ç‡: 0.9709\n",
      "éªŒè¯æŸå¤±: 0.0737, éªŒè¯å‡†ç¡®ç‡: 0.9760\n",
      "å­¦ä¹ ç‡: 0.000100\n",
      "\n",
      "Epoch 12/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:50<00:00,  9.81it/s, Loss=0.0299, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.44it/s, Loss=0.0036, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0831, è®­ç»ƒå‡†ç¡®ç‡: 0.9727\n",
      "éªŒè¯æŸå¤±: 0.0676, éªŒè¯å‡†ç¡®ç‡: 0.9782\n",
      "å­¦ä¹ ç‡: 0.000099\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_12.pth (å‡†ç¡®ç‡: 0.9782)\n",
      "\n",
      "Epoch 13/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:47<00:00,  9.86it/s, Loss=0.1155, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:47<00:00, 17.64it/s, Loss=0.0067, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0822, è®­ç»ƒå‡†ç¡®ç‡: 0.9728\n",
      "éªŒè¯æŸå¤±: 0.0655, éªŒè¯å‡†ç¡®ç‡: 0.9791\n",
      "å­¦ä¹ ç‡: 0.000098\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_13.pth (å‡†ç¡®ç‡: 0.9791)\n",
      "\n",
      "Epoch 14/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:41<00:00,  9.94it/s, Loss=0.1479, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.33it/s, Loss=0.0135, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0797, è®­ç»ƒå‡†ç¡®ç‡: 0.9736\n",
      "éªŒè¯æŸå¤±: 0.0675, éªŒè¯å‡†ç¡®ç‡: 0.9777\n",
      "å­¦ä¹ ç‡: 0.000098\n",
      "\n",
      "Epoch 15/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:47<00:00,  9.85it/s, Loss=0.0794, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.13it/s, Loss=0.0059, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0759, è®­ç»ƒå‡†ç¡®ç‡: 0.9750\n",
      "éªŒè¯æŸå¤±: 0.0650, éªŒè¯å‡†ç¡®ç‡: 0.9788\n",
      "å­¦ä¹ ç‡: 0.000097\n",
      "\n",
      "Epoch 16/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:57<00:00,  9.70it/s, Loss=0.0271, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:51<00:00, 16.50it/s, Loss=0.0162, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0734, è®­ç»ƒå‡†ç¡®ç‡: 0.9757\n",
      "éªŒè¯æŸå¤±: 0.0639, éªŒè¯å‡†ç¡®ç‡: 0.9792\n",
      "å­¦ä¹ ç‡: 0.000097\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_16.pth (å‡†ç¡®ç‡: 0.9792)\n",
      "\n",
      "Epoch 17/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:57<00:00,  9.71it/s, Loss=0.0028, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.52it/s, Loss=0.0115, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0722, è®­ç»ƒå‡†ç¡®ç‡: 0.9761\n",
      "éªŒè¯æŸå¤±: 0.0617, éªŒè¯å‡†ç¡®ç‡: 0.9799\n",
      "å­¦ä¹ ç‡: 0.000096\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_17.pth (å‡†ç¡®ç‡: 0.9799)\n",
      "\n",
      "Epoch 18/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:51<00:00,  9.80it/s, Loss=0.0298, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.56it/s, Loss=0.0044, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0715, è®­ç»ƒå‡†ç¡®ç‡: 0.9763\n",
      "éªŒè¯æŸå¤±: 0.0624, éªŒè¯å‡†ç¡®ç‡: 0.9796\n",
      "å­¦ä¹ ç‡: 0.000095\n",
      "\n",
      "Epoch 19/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [11:00<00:00,  9.66it/s, Loss=0.2679, Acc=0.9259]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:51<00:00, 16.51it/s, Loss=0.0038, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0697, è®­ç»ƒå‡†ç¡®ç‡: 0.9771\n",
      "éªŒè¯æŸå¤±: 0.0627, éªŒè¯å‡†ç¡®ç‡: 0.9797\n",
      "å­¦ä¹ ç‡: 0.000094\n",
      "\n",
      "Epoch 20/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:45<00:00,  9.89it/s, Loss=0.2429, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.13it/s, Loss=0.0053, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0680, è®­ç»ƒå‡†ç¡®ç‡: 0.9777\n",
      "éªŒè¯æŸå¤±: 0.0614, éªŒè¯å‡†ç¡®ç‡: 0.9796\n",
      "å­¦ä¹ ç‡: 0.000093\n",
      "ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: /mnt/MCP/gesture_models/checkpoints/checkpoint_epoch_20.pth\n",
      "\n",
      "Epoch 21/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:50<00:00,  9.81it/s, Loss=0.0733, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.54it/s, Loss=0.0070, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0669, è®­ç»ƒå‡†ç¡®ç‡: 0.9781\n",
      "éªŒè¯æŸå¤±: 0.0635, éªŒè¯å‡†ç¡®ç‡: 0.9797\n",
      "å­¦ä¹ ç‡: 0.000092\n",
      "\n",
      "Epoch 22/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:40<00:00,  9.96it/s, Loss=0.1970, Acc=0.9259]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.54it/s, Loss=0.0035, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0659, è®­ç»ƒå‡†ç¡®ç‡: 0.9783\n",
      "éªŒè¯æŸå¤±: 0.0615, éªŒè¯å‡†ç¡®ç‡: 0.9797\n",
      "å­¦ä¹ ç‡: 0.000091\n",
      "\n",
      "Epoch 23/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:37<00:00, 10.01it/s, Loss=0.0622, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.23it/s, Loss=0.0097, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0654, è®­ç»ƒå‡†ç¡®ç‡: 0.9785\n",
      "éªŒè¯æŸå¤±: 0.0605, éªŒè¯å‡†ç¡®ç‡: 0.9810\n",
      "å­¦ä¹ ç‡: 0.000090\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_23.pth (å‡†ç¡®ç‡: 0.9810)\n",
      "\n",
      "Epoch 24/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:50<00:00,  9.80it/s, Loss=0.3632, Acc=0.8889]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:47<00:00, 17.59it/s, Loss=0.0046, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0635, è®­ç»ƒå‡†ç¡®ç‡: 0.9790\n",
      "éªŒè¯æŸå¤±: 0.0633, éªŒè¯å‡†ç¡®ç‡: 0.9800\n",
      "å­¦ä¹ ç‡: 0.000089\n",
      "\n",
      "Epoch 25/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:40<00:00,  9.96it/s, Loss=0.0018, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.51it/s, Loss=0.0029, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0635, è®­ç»ƒå‡†ç¡®ç‡: 0.9791\n",
      "éªŒè¯æŸå¤±: 0.0610, éªŒè¯å‡†ç¡®ç‡: 0.9803\n",
      "å­¦ä¹ ç‡: 0.000088\n",
      "\n",
      "Epoch 26/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:42<00:00,  9.93it/s, Loss=0.0196, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.33it/s, Loss=0.0046, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0599, è®­ç»ƒå‡†ç¡®ç‡: 0.9805\n",
      "éªŒè¯æŸå¤±: 0.0571, éªŒè¯å‡†ç¡®ç‡: 0.9817\n",
      "å­¦ä¹ ç‡: 0.000087\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_26.pth (å‡†ç¡®ç‡: 0.9817)\n",
      "\n",
      "Epoch 27/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:50<00:00,  9.81it/s, Loss=0.2082, Acc=0.9259]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.55it/s, Loss=0.0032, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0609, è®­ç»ƒå‡†ç¡®ç‡: 0.9798\n",
      "éªŒè¯æŸå¤±: 0.0606, éªŒè¯å‡†ç¡®ç‡: 0.9800\n",
      "å­¦ä¹ ç‡: 0.000086\n",
      "\n",
      "Epoch 28/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:40<00:00,  9.96it/s, Loss=0.1884, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.55it/s, Loss=0.0050, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0597, è®­ç»ƒå‡†ç¡®ç‡: 0.9802\n",
      "éªŒè¯æŸå¤±: 0.0582, éªŒè¯å‡†ç¡®ç‡: 0.9820\n",
      "å­¦ä¹ ç‡: 0.000085\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_28.pth (å‡†ç¡®ç‡: 0.9820)\n",
      "\n",
      "Epoch 29/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:49<00:00,  9.83it/s, Loss=0.0473, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:47<00:00, 17.72it/s, Loss=0.0052, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0580, è®­ç»ƒå‡†ç¡®ç‡: 0.9810\n",
      "éªŒè¯æŸå¤±: 0.0587, éªŒè¯å‡†ç¡®ç‡: 0.9813\n",
      "å­¦ä¹ ç‡: 0.000084\n",
      "\n",
      "Epoch 30/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:50<00:00,  9.80it/s, Loss=0.0499, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.50it/s, Loss=0.0079, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0584, è®­ç»ƒå‡†ç¡®ç‡: 0.9806\n",
      "éªŒè¯æŸå¤±: 0.0606, éªŒè¯å‡†ç¡®ç‡: 0.9802\n",
      "å­¦ä¹ ç‡: 0.000082\n",
      "ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: /mnt/MCP/gesture_models/checkpoints/checkpoint_epoch_30.pth\n",
      "\n",
      "Epoch 31/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:52<00:00,  9.78it/s, Loss=0.0462, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.22it/s, Loss=0.0113, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0577, è®­ç»ƒå‡†ç¡®ç‡: 0.9809\n",
      "éªŒè¯æŸå¤±: 0.0636, éªŒè¯å‡†ç¡®ç‡: 0.9793\n",
      "å­¦ä¹ ç‡: 0.000081\n",
      "\n",
      "Epoch 32/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:53<00:00,  9.76it/s, Loss=0.0064, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.50it/s, Loss=0.0014, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0560, è®­ç»ƒå‡†ç¡®ç‡: 0.9814\n",
      "éªŒè¯æŸå¤±: 0.0592, éªŒè¯å‡†ç¡®ç‡: 0.9807\n",
      "å­¦ä¹ ç‡: 0.000080\n",
      "\n",
      "Epoch 33/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:51<00:00,  9.79it/s, Loss=0.0029, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.56it/s, Loss=0.0048, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0552, è®­ç»ƒå‡†ç¡®ç‡: 0.9816\n",
      "éªŒè¯æŸå¤±: 0.0582, éªŒè¯å‡†ç¡®ç‡: 0.9824\n",
      "å­¦ä¹ ç‡: 0.000079\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_33.pth (å‡†ç¡®ç‡: 0.9824)\n",
      "\n",
      "Epoch 34/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:49<00:00,  9.82it/s, Loss=0.0047, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.54it/s, Loss=0.0098, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0548, è®­ç»ƒå‡†ç¡®ç‡: 0.9817\n",
      "éªŒè¯æŸå¤±: 0.0553, éªŒè¯å‡†ç¡®ç‡: 0.9826\n",
      "å­¦ä¹ ç‡: 0.000077\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_34.pth (å‡†ç¡®ç‡: 0.9826)\n",
      "\n",
      "Epoch 35/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:42<00:00,  9.94it/s, Loss=0.1041, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.57it/s, Loss=0.0122, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0536, è®­ç»ƒå‡†ç¡®ç‡: 0.9823\n",
      "éªŒè¯æŸå¤±: 0.0597, éªŒè¯å‡†ç¡®ç‡: 0.9810\n",
      "å­¦ä¹ ç‡: 0.000076\n",
      "\n",
      "Epoch 36/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:45<00:00,  9.89it/s, Loss=0.0016, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:52<00:00, 16.17it/s, Loss=0.0038, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0527, è®­ç»ƒå‡†ç¡®ç‡: 0.9825\n",
      "éªŒè¯æŸå¤±: 0.0561, éªŒè¯å‡†ç¡®ç‡: 0.9824\n",
      "å­¦ä¹ ç‡: 0.000074\n",
      "\n",
      "Epoch 37/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [11:10<00:00,  9.52it/s, Loss=0.0930, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:51<00:00, 16.43it/s, Loss=0.0046, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0526, è®­ç»ƒå‡†ç¡®ç‡: 0.9826\n",
      "éªŒè¯æŸå¤±: 0.0577, éªŒè¯å‡†ç¡®ç‡: 0.9817\n",
      "å­¦ä¹ ç‡: 0.000073\n",
      "\n",
      "Epoch 38/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:52<00:00,  9.77it/s, Loss=0.0088, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.56it/s, Loss=0.0015, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0508, è®­ç»ƒå‡†ç¡®ç‡: 0.9830\n",
      "éªŒè¯æŸå¤±: 0.0566, éªŒè¯å‡†ç¡®ç‡: 0.9831\n",
      "å­¦ä¹ ç‡: 0.000072\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_38.pth (å‡†ç¡®ç‡: 0.9831)\n",
      "\n",
      "Epoch 39/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:42<00:00,  9.93it/s, Loss=0.2067, Acc=0.9259]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.16it/s, Loss=0.0022, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0524, è®­ç»ƒå‡†ç¡®ç‡: 0.9827\n",
      "éªŒè¯æŸå¤±: 0.0586, éªŒè¯å‡†ç¡®ç‡: 0.9811\n",
      "å­¦ä¹ ç‡: 0.000070\n",
      "\n",
      "Epoch 40/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:49<00:00,  9.82it/s, Loss=0.0024, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.25it/s, Loss=0.0025, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0497, è®­ç»ƒå‡†ç¡®ç‡: 0.9834\n",
      "éªŒè¯æŸå¤±: 0.0592, éªŒè¯å‡†ç¡®ç‡: 0.9812\n",
      "å­¦ä¹ ç‡: 0.000069\n",
      "ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: /mnt/MCP/gesture_models/checkpoints/checkpoint_epoch_40.pth\n",
      "\n",
      "Epoch 41/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:49<00:00,  9.83it/s, Loss=0.0739, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.18it/s, Loss=0.0018, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0500, è®­ç»ƒå‡†ç¡®ç‡: 0.9836\n",
      "éªŒè¯æŸå¤±: 0.0572, éªŒè¯å‡†ç¡®ç‡: 0.9824\n",
      "å­¦ä¹ ç‡: 0.000067\n",
      "\n",
      "Epoch 42/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:51<00:00,  9.80it/s, Loss=0.0987, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:47<00:00, 17.59it/s, Loss=0.0023, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0487, è®­ç»ƒå‡†ç¡®ç‡: 0.9837\n",
      "éªŒè¯æŸå¤±: 0.0558, éªŒè¯å‡†ç¡®ç‡: 0.9818\n",
      "å­¦ä¹ ç‡: 0.000066\n",
      "\n",
      "Epoch 43/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:42<00:00,  9.94it/s, Loss=0.0150, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:47<00:00, 17.62it/s, Loss=0.0031, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0477, è®­ç»ƒå‡†ç¡®ç‡: 0.9843\n",
      "éªŒè¯æŸå¤±: 0.0516, éªŒè¯å‡†ç¡®ç‡: 0.9833\n",
      "å­¦ä¹ ç‡: 0.000064\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_43.pth (å‡†ç¡®ç‡: 0.9833)\n",
      "\n",
      "Epoch 44/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:42<00:00,  9.93it/s, Loss=0.1850, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:47<00:00, 17.71it/s, Loss=0.0030, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0462, è®­ç»ƒå‡†ç¡®ç‡: 0.9844\n",
      "éªŒè¯æŸå¤±: 0.0571, éªŒè¯å‡†ç¡®ç‡: 0.9817\n",
      "å­¦ä¹ ç‡: 0.000063\n",
      "\n",
      "Epoch 45/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:51<00:00,  9.80it/s, Loss=0.0966, Acc=0.9259]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:47<00:00, 17.67it/s, Loss=0.0130, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0459, è®­ç»ƒå‡†ç¡®ç‡: 0.9847\n",
      "éªŒè¯æŸå¤±: 0.0589, éªŒè¯å‡†ç¡®ç‡: 0.9818\n",
      "å­¦ä¹ ç‡: 0.000061\n",
      "\n",
      "Epoch 46/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:43<00:00,  9.92it/s, Loss=0.0123, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.14it/s, Loss=0.0007, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0459, è®­ç»ƒå‡†ç¡®ç‡: 0.9847\n",
      "éªŒè¯æŸå¤±: 0.0547, éªŒè¯å‡†ç¡®ç‡: 0.9828\n",
      "å­¦ä¹ ç‡: 0.000059\n",
      "\n",
      "Epoch 47/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:56<00:00,  9.73it/s, Loss=0.0183, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:52<00:00, 16.22it/s, Loss=0.0027, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0449, è®­ç»ƒå‡†ç¡®ç‡: 0.9851\n",
      "éªŒè¯æŸå¤±: 0.0554, éªŒè¯å‡†ç¡®ç‡: 0.9832\n",
      "å­¦ä¹ ç‡: 0.000058\n",
      "\n",
      "Epoch 48/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [11:03<00:00,  9.62it/s, Loss=0.0046, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.09it/s, Loss=0.0008, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0447, è®­ç»ƒå‡†ç¡®ç‡: 0.9849\n",
      "éªŒè¯æŸå¤±: 0.0554, éªŒè¯å‡†ç¡®ç‡: 0.9832\n",
      "å­¦ä¹ ç‡: 0.000056\n",
      "\n",
      "Epoch 49/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:51<00:00,  9.79it/s, Loss=0.0071, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.13it/s, Loss=0.0020, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0433, è®­ç»ƒå‡†ç¡®ç‡: 0.9855\n",
      "éªŒè¯æŸå¤±: 0.0524, éªŒè¯å‡†ç¡®ç‡: 0.9834\n",
      "å­¦ä¹ ç‡: 0.000055\n",
      "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: /mnt/MCP/gesture_models/checkpoints/best_model_epoch_49.pth (å‡†ç¡®ç‡: 0.9834)\n",
      "\n",
      "Epoch 50/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [11:08<00:00,  9.55it/s, Loss=0.1342, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:52<00:00, 16.21it/s, Loss=0.0060, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0427, è®­ç»ƒå‡†ç¡®ç‡: 0.9858\n",
      "éªŒè¯æŸå¤±: 0.0548, éªŒè¯å‡†ç¡®ç‡: 0.9828\n",
      "å­¦ä¹ ç‡: 0.000053\n",
      "ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: /mnt/MCP/gesture_models/checkpoints/checkpoint_epoch_50.pth\n",
      "\n",
      "Epoch 51/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:56<00:00,  9.72it/s, Loss=0.0790, Acc=0.9630]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.51it/s, Loss=0.0021, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0421, è®­ç»ƒå‡†ç¡®ç‡: 0.9862\n",
      "éªŒè¯æŸå¤±: 0.0516, éªŒè¯å‡†ç¡®ç‡: 0.9834\n",
      "å­¦ä¹ ç‡: 0.000052\n",
      "\n",
      "Epoch 52/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:50<00:00,  9.81it/s, Loss=0.0137, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:48<00:00, 17.24it/s, Loss=0.0011, Acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0415, è®­ç»ƒå‡†ç¡®ç‡: 0.9863\n",
      "éªŒè¯æŸå¤±: 0.0543, éªŒè¯å‡†ç¡®ç‡: 0.9828\n",
      "å­¦ä¹ ç‡: 0.000050\n",
      "\n",
      "Epoch 53/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6381/6381 [10:49<00:00,  9.82it/s, Loss=0.0019, Acc=1.0000]\n",
      "éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [00:49<00:00, 17.22it/s, Loss=0.0031, Acc=1.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 0.0410, è®­ç»ƒå‡†ç¡®ç‡: 0.9860\n",
      "éªŒè¯æŸå¤±: 0.0514, éªŒè¯å‡†ç¡®ç‡: 0.9835\n",
      "å­¦ä¹ ç‡: 0.000048\n",
      "ğŸš¨ æ—©åœè§¦å‘! åœ¨ 53 ä¸ªepochååœæ­¢è®­ç»ƒ\n",
      "âœ… å·²æ¢å¤ç¬¬ 38 ä¸ªepochçš„æœ€ä½³æ¨¡å‹\n",
      "ğŸ¯ è®­ç»ƒæå‰ç»“æŸï¼Œæœ€ä½³éªŒè¯å‡†ç¡®ç‡: 0.9831 (ç¬¬ 38 ä¸ªepoch)\n",
      "\n",
      "ğŸ‰ è®­ç»ƒå®Œæˆ!\n",
      "æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: 0.9835\n",
      "æœ€ä½³éªŒè¯å‡†ç¡®ç‡: 0.9834 (ç¬¬ 49 ä¸ªepoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ä»æœ€ä½³æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ\n",
    "def continue_training_from_checkpoint(model, optimizer, scheduler, checkpoint_dir, num_epochs, device):\n",
    "    \"\"\"ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ\"\"\"\n",
    "    print(\"\\nğŸ”„ ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # æŸ¥æ‰¾æœ€æ–°çš„æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹\n",
    "    checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.startswith('best_model_epoch_')]\n",
    "    \n",
    "    if checkpoint_files:\n",
    "        latest_checkpoint = sorted(checkpoint_files)[-1]\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "        \n",
    "        print(f\"ğŸ“ åŠ è½½æ£€æŸ¥ç‚¹: {latest_checkpoint}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        \n",
    "        # åŠ è½½æ¨¡å‹çŠ¶æ€\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        # åŠ è½½è°ƒåº¦å™¨çŠ¶æ€\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        \n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_val_acc = checkpoint['val_acc']\n",
    "        best_epoch = start_epoch\n",
    "        \n",
    "        print(f\"âœ… ä»ç¬¬ {start_epoch} ä¸ªepochç»§ç»­è®­ç»ƒ\")\n",
    "        print(f\"   å½“å‰æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}\")\n",
    "        \n",
    "        return model, optimizer, scheduler, start_epoch, best_val_acc, best_epoch\n",
    "    else:\n",
    "        print(\"âŒ æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ\")\n",
    "        return model, optimizer, scheduler, 0, 0.0, 0\n",
    "\n",
    "# åŠ è½½æ£€æŸ¥ç‚¹\n",
    "model, optimizer, scheduler, start_epoch, best_val_acc, best_epoch = continue_training_from_checkpoint(\n",
    "    model, optimizer, scheduler, checkpoint_dir, num_epochs, device\n",
    ")\n",
    "\n",
    "# é‡æ–°å¼€å§‹è®­ç»ƒå¾ªç¯\n",
    "print(f\"\\nğŸš€ ç»§ç»­è®­ç»ƒåˆ° {num_epochs} ä¸ªepoch\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# è®­ç»ƒå†å²è®°å½•\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # è®­ç»ƒä¸€ä¸ªepoch\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # éªŒè¯ä¸€ä¸ªepoch\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # æ›´æ–°å­¦ä¹ ç‡\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step()\n",
    "    \n",
    "    # è®°å½•å†å²\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc.cpu().numpy())\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc.cpu().numpy())\n",
    "    history['learning_rates'].append(current_lr)\n",
    "    \n",
    "    print(f\"è®­ç»ƒæŸå¤±: {train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}\")\n",
    "    print(f\"éªŒè¯æŸå¤±: {val_loss:.4f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}\")\n",
    "    print(f\"å­¦ä¹ ç‡: {current_lr:.6f}\")\n",
    "    \n",
    "    # æ£€æŸ¥æ—©åœ\n",
    "    if early_stopping(val_acc, epoch+1, model):\n",
    "        print(f\"ğŸ¯ è®­ç»ƒæå‰ç»“æŸï¼Œæœ€ä½³éªŒè¯å‡†ç¡®ç‡: {early_stopping.best_val_acc:.4f} (ç¬¬ {early_stopping.best_epoch} ä¸ªepoch)\")\n",
    "        break\n",
    "    \n",
    "    # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch + 1\n",
    "        \n",
    "        # ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'train_loss': train_loss\n",
    "        }\n",
    "        \n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'best_model_epoch_{epoch+1}.pth')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: {checkpoint_path} (å‡†ç¡®ç‡: {val_acc:.4f})\")\n",
    "    \n",
    "    # æ¯10ä¸ªepochä¿å­˜ä¸€æ¬¡å¸¸è§„æ£€æŸ¥ç‚¹\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ è®­ç»ƒå®Œæˆ!\")\n",
    "print(f\"æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}\")\n",
    "print(f\"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f} (ç¬¬ {best_epoch} ä¸ªepoch)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c4c785d-b0d9-4c14-ac1a-3fef664746ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ ç”Ÿæˆå®éªŒç¯å¢ƒã€æ¨¡å‹æ¶æ„å’Œå‚æ•°é…ç½®æŠ¥å‘Š\n",
      "============================================================\n",
      "âœ… å®éªŒæŠ¥å‘Šå·²ä¿å­˜:\n",
      "   JSONæ ¼å¼: /mnt/MCP/gesture_models/experiment_report.json\n",
      "   æ–‡æœ¬æ ¼å¼: /mnt/MCP/gesture_models/experiment_report.txt\n",
      "\n",
      "================================================================================\n",
      "                    å®éªŒæ‘˜è¦\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š æ€§èƒ½æŒ‡æ ‡:\n",
      "   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: 0.9834\n",
      "   æœ€ä½³è®­ç»ƒå‡†ç¡®ç‡: 0.9863\n",
      "   æœ€ä½³epoch: 49\n",
      "   æ€»è®­ç»ƒè½®æ•°: 44\n",
      "\n",
      "ğŸ¤– æ¨¡å‹ä¿¡æ¯:\n",
      "   æ¶æ„: ResNet18\n",
      "   å‚æ•°é‡: 11,181,129\n",
      "   è¾“å…¥å°ºå¯¸: (3, 224, 224)\n",
      "   è¾“å‡ºç±»åˆ«: 9\n",
      "\n",
      "âš™ï¸ è®­ç»ƒé…ç½®:\n",
      "   è®¾å¤‡: cuda\n",
      "   ä¼˜åŒ–å™¨: Adam\n",
      "   å­¦ä¹ ç‡: 0.001\n",
      "   æ‰¹æ¬¡å¤§å°: 32\n",
      "\n",
      "ğŸ“ æ•°æ®é›†:\n",
      "   ç±»åˆ«æ•°: 9\n",
      "   è®­ç»ƒé›†: 204187 æ ·æœ¬\n",
      "   éªŒè¯é›†: 26990 æ ·æœ¬\n",
      "\n",
      "ğŸ’¡ ç³»ç»Ÿç¯å¢ƒ:\n",
      "   PyTorch: 2.1.1+cu118\n",
      "   CUDA: True\n",
      "   GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "def generate_experiment_report(model, history, class_names, model_dir, best_epoch, best_val_acc):\n",
    "    \"\"\"ç”Ÿæˆè¯¦ç»†çš„å®éªŒç¯å¢ƒã€æ¨¡å‹æ¶æ„å’Œå‚æ•°é…ç½®æŠ¥å‘Š\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“‹ ç”Ÿæˆå®éªŒç¯å¢ƒã€æ¨¡å‹æ¶æ„å’Œå‚æ•°é…ç½®æŠ¥å‘Š\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "    system_info = {\n",
    "        \"ç”Ÿæˆæ—¶é—´\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"Pythonç‰ˆæœ¬\": platform.python_version(),\n",
    "        \"æ“ä½œç³»ç»Ÿ\": f\"{platform.system()} {platform.release()}\",\n",
    "        \"å¤„ç†å™¨\": platform.processor(),\n",
    "        \"å†…å­˜æ€»é‡\": f\"{psutil.virtual_memory().total / (1024**3):.2f} GB\",\n",
    "        \"PyTorchç‰ˆæœ¬\": torch.__version__,\n",
    "        \"Torchvisionç‰ˆæœ¬\": torchvision.__version__,\n",
    "        \"CUDAå¯ç”¨\": torch.cuda.is_available(),\n",
    "        \"CUDAç‰ˆæœ¬\": torch.version.cuda if torch.cuda.is_available() else \"N/A\",\n",
    "        \"GPUè®¾å¤‡\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n",
    "    }\n",
    "    \n",
    "    # æ•°æ®é›†ä¿¡æ¯\n",
    "    dataset_info = {\n",
    "        \"æ•°æ®é›†åç§°\": \"Hagridæ‰‹åŠ¿åˆ†ç±»æ•°æ®é›†\",\n",
    "        \"æ•°æ®é›†è·¯å¾„\": \"/mnt/MCP/hagrid_classification\",\n",
    "        \"æ€»ç±»åˆ«æ•°\": len(class_names),\n",
    "        \"ç±»åˆ«åç§°\": class_names,\n",
    "        \"è®­ç»ƒé›†å¤§å°\": len(train_loader.dataset),\n",
    "        \"éªŒè¯é›†å¤§å°\": len(val_loader.dataset),\n",
    "        \"æµ‹è¯•é›†å¤§å°\": len(test_loader.dataset) if 'test_loader' in locals() else \"æœªåŠ è½½\"\n",
    "    }\n",
    "    \n",
    "    # æ¨¡å‹æ¶æ„ä¿¡æ¯\n",
    "    model_architecture = {\n",
    "        \"åŸºç¡€æ¨¡å‹\": \"ResNet18\",\n",
    "        \"é¢„è®­ç»ƒæƒé‡\": True,\n",
    "        \"è¾“å…¥å°ºå¯¸\": \"(3, 224, 224)\",\n",
    "        \"è¾“å‡ºç»´åº¦\": num_classes,\n",
    "        \"ä¿®æ”¹çš„å…¨è¿æ¥å±‚\": f\"{model.fc.in_features} -> {model.fc.out_features}\",\n",
    "        \"æ€»å‚æ•°é‡\": f\"{sum(p.numel() for p in model.parameters()):,}\",\n",
    "        \"å¯è®­ç»ƒå‚æ•°é‡\": f\"{sum(p.numel() for p in model.parameters() if p.requires_grad):,}\"\n",
    "    }\n",
    "    \n",
    "    # è®­ç»ƒé…ç½®\n",
    "    training_config = {\n",
    "        \"è®¾å¤‡\": str(device),\n",
    "        \"è®­ç»ƒè½®æ•°\": f\"{num_epochs} (å®é™…è®­ç»ƒ: {best_epoch})\",\n",
    "        \"æ‰¹æ¬¡å¤§å°\": train_loader.batch_size,\n",
    "        \"æŸå¤±å‡½æ•°\": \"CrossEntropyLoss\",\n",
    "        \"ä¼˜åŒ–å™¨\": \"Adam\",\n",
    "        \"åˆå§‹å­¦ä¹ ç‡\": 0.001,\n",
    "        \"æƒé‡è¡°å‡\": 1e-3,\n",
    "        \"å­¦ä¹ ç‡è°ƒåº¦å™¨\": \"CosineAnnealingLR\",\n",
    "        \"æ—©åœæœºåˆ¶\": \"patience=15, min_delta=0.001\",\n",
    "        \"æ•°æ®åŠ è½½Workers\": train_loader.num_workers\n",
    "    }\n",
    "    \n",
    "    # æ•°æ®é¢„å¤„ç†å’Œå¢å¼º\n",
    "    data_transforms = {\n",
    "        \"è®­ç»ƒé›†å¢å¼º\": [\n",
    "            \"Resize(256, 256)\",\n",
    "            \"RandomCrop(224)\",\n",
    "            \"RandomHorizontalFlip(p=0.5)\",\n",
    "            \"RandomRotation(10)\",\n",
    "            \"ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\",\n",
    "            \"ToTensor()\",\n",
    "            \"Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\"\n",
    "        ],\n",
    "        \"éªŒè¯é›†è½¬æ¢\": [\n",
    "            \"Resize(256, 256)\",\n",
    "            \"CenterCrop(224)\",\n",
    "            \"ToTensor()\",\n",
    "            \"Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # è®­ç»ƒç»“æœ - å°†numpyæ•°ç»„è½¬æ¢ä¸ºPythonåˆ—è¡¨\n",
    "    training_results = {\n",
    "        \"æœ€ä½³éªŒè¯å‡†ç¡®ç‡\": f\"{best_val_acc:.4f}\",\n",
    "        \"æœ€ä½³è®­ç»ƒå‡†ç¡®ç‡\": f\"{max(history['train_acc']):.4f}\",\n",
    "        \"æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡\": f\"{history['val_acc'][-1]:.4f}\",\n",
    "        \"æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡\": f\"{history['train_acc'][-1]:.4f}\",\n",
    "        \"æœ€ä½³epoch\": best_epoch,\n",
    "        \"æ€»è®­ç»ƒepoch\": len(history['train_loss']),\n",
    "        \"æ—©åœè§¦å‘\": len(history['train_loss']) < num_epochs,\n",
    "        \"æœ€ç»ˆå­¦ä¹ ç‡\": f\"{history['learning_rates'][-1]:.8f}\"\n",
    "    }\n",
    "    \n",
    "    # æ€§èƒ½æŒ‡æ ‡ - å°†numpyæ•°ç»„è½¬æ¢ä¸ºPythonåˆ—è¡¨\n",
    "    performance_metrics = {\n",
    "        \"è®­ç»ƒæŸå¤±æ›²çº¿\": [float(x) for x in history['train_loss']],\n",
    "        \"éªŒè¯æŸå¤±æ›²çº¿\": [float(x) for x in history['val_loss']],\n",
    "        \"è®­ç»ƒå‡†ç¡®ç‡æ›²çº¿\": [float(x) for x in history['train_acc']],\n",
    "        \"éªŒè¯å‡†ç¡®ç‡æ›²çº¿\": [float(x) for x in history['val_acc']],\n",
    "        \"å­¦ä¹ ç‡å˜åŒ–æ›²çº¿\": [float(x) for x in history['learning_rates']]\n",
    "    }\n",
    "    \n",
    "    # ç¼–è¯‘å®Œæ•´æŠ¥å‘Š\n",
    "    experiment_report = {\n",
    "        \"å®éªŒæ¦‚è¿°\": {\n",
    "            \"é¡¹ç›®åç§°\": \"åŸºäºResNet18çš„æ‰‹åŠ¿åˆ†ç±»æ¨¡å‹\",\n",
    "            \"å®éªŒç›®æ ‡\": \"è®­ç»ƒä¸€ä¸ªèƒ½å¤Ÿè¯†åˆ«9ç§åŒ»ç–—æ‰‹åŠ¿çš„æ·±åº¦å­¦ä¹ æ¨¡å‹\",\n",
    "            \"å®éªŒæ—¥æœŸ\": system_info[\"ç”Ÿæˆæ—¶é—´\"]\n",
    "        },\n",
    "        \"ç³»ç»Ÿç¯å¢ƒ\": system_info,\n",
    "        \"æ•°æ®é›†\": dataset_info,\n",
    "        \"æ¨¡å‹æ¶æ„\": model_architecture,\n",
    "        \"è®­ç»ƒé…ç½®\": training_config,\n",
    "        \"æ•°æ®é¢„å¤„ç†\": data_transforms,\n",
    "        \"è®­ç»ƒç»“æœ\": training_results,\n",
    "        \"æ€§èƒ½æŒ‡æ ‡\": performance_metrics\n",
    "    }\n",
    "    \n",
    "    return experiment_report\n",
    "\n",
    "def save_experiment_report(report, model_dir):\n",
    "    \"\"\"ä¿å­˜å®éªŒæŠ¥å‘Šåˆ°æ–‡ä»¶\"\"\"\n",
    "    \n",
    "    # ä¿å­˜ä¸ºJSONæ–‡ä»¶\n",
    "    json_path = os.path.join(model_dir, \"experiment_report.json\")\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # ä¿å­˜ä¸ºå¯è¯»çš„æ–‡æœ¬æ–‡ä»¶\n",
    "    txt_path = os.path.join(model_dir, \"experiment_report.txt\")\n",
    "    with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\" * 80 + \"\\n\")\n",
    "        f.write(\"                   æ‰‹åŠ¿åˆ†ç±»å®éªŒæŠ¥å‘Š\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "        \n",
    "        # å®éªŒæ¦‚è¿°\n",
    "        f.write(\"1. å®éªŒæ¦‚è¿°\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        for key, value in report[\"å®éªŒæ¦‚è¿°\"].items():\n",
    "            f.write(f\"   {key}: {value}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # ç³»ç»Ÿç¯å¢ƒ\n",
    "        f.write(\"2. ç³»ç»Ÿç¯å¢ƒ\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        for key, value in report[\"ç³»ç»Ÿç¯å¢ƒ\"].items():\n",
    "            f.write(f\"   {key}: {value}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # æ•°æ®é›†\n",
    "        f.write(\"3. æ•°æ®é›†ä¿¡æ¯\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        for key, value in report[\"æ•°æ®é›†\"].items():\n",
    "            if key == \"ç±»åˆ«åç§°\":\n",
    "                f.write(f\"   {key}: {', '.join(value)}\\n\")\n",
    "            else:\n",
    "                f.write(f\"   {key}: {value}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # æ¨¡å‹æ¶æ„\n",
    "        f.write(\"4. æ¨¡å‹æ¶æ„\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        for key, value in report[\"æ¨¡å‹æ¶æ„\"].items():\n",
    "            f.write(f\"   {key}: {value}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # è®­ç»ƒé…ç½®\n",
    "        f.write(\"5. è®­ç»ƒé…ç½®\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        for key, value in report[\"è®­ç»ƒé…ç½®\"].items():\n",
    "            f.write(f\"   {key}: {value}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # æ•°æ®é¢„å¤„ç†\n",
    "        f.write(\"6. æ•°æ®é¢„å¤„ç†\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(\"   è®­ç»ƒé›†å¢å¼º:\\n\")\n",
    "        for transform in report[\"æ•°æ®é¢„å¤„ç†\"][\"è®­ç»ƒé›†å¢å¼º\"]:\n",
    "            f.write(f\"     - {transform}\\n\")\n",
    "        f.write(\"   éªŒè¯é›†è½¬æ¢:\\n\")\n",
    "        for transform in report[\"æ•°æ®é¢„å¤„ç†\"][\"éªŒè¯é›†è½¬æ¢\"]:\n",
    "            f.write(f\"     - {transform}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # è®­ç»ƒç»“æœ\n",
    "        f.write(\"7. è®­ç»ƒç»“æœ\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        for key, value in report[\"è®­ç»ƒç»“æœ\"].items():\n",
    "            f.write(f\"   {key}: {value}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # å…³é”®æŒ‡æ ‡æ€»ç»“\n",
    "        f.write(\"8. å…³é”®æŒ‡æ ‡æ€»ç»“\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(f\"   âœ… æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {report['è®­ç»ƒç»“æœ']['æœ€ä½³éªŒè¯å‡†ç¡®ç‡']}\\n\")\n",
    "        f.write(f\"   âœ… è®­ç»ƒè½®æ•°: {report['è®­ç»ƒç»“æœ']['æ€»è®­ç»ƒepoch']}/{report['è®­ç»ƒé…ç½®']['è®­ç»ƒè½®æ•°'].split(' ')[0]}\\n\")\n",
    "        f.write(f\"   âœ… æ¨¡å‹å¤§å°: {report['æ¨¡å‹æ¶æ„']['æ€»å‚æ•°é‡']} å‚æ•°\\n\")\n",
    "        f.write(f\"   âœ… è®¾å¤‡: {report['ç³»ç»Ÿç¯å¢ƒ']['GPUè®¾å¤‡']}\\n\")\n",
    "    \n",
    "    print(f\"âœ… å®éªŒæŠ¥å‘Šå·²ä¿å­˜:\")\n",
    "    print(f\"   JSONæ ¼å¼: {json_path}\")\n",
    "    print(f\"   æ–‡æœ¬æ ¼å¼: {txt_path}\")\n",
    "    \n",
    "    return json_path, txt_path\n",
    "\n",
    "def print_experiment_summary(report):\n",
    "    \"\"\"æ‰“å°å®éªŒæ‘˜è¦\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"                    å®éªŒæ‘˜è¦\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š æ€§èƒ½æŒ‡æ ‡:\")\n",
    "    print(f\"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {report['è®­ç»ƒç»“æœ']['æœ€ä½³éªŒè¯å‡†ç¡®ç‡']}\")\n",
    "    print(f\"   æœ€ä½³è®­ç»ƒå‡†ç¡®ç‡: {report['è®­ç»ƒç»“æœ']['æœ€ä½³è®­ç»ƒå‡†ç¡®ç‡']}\")\n",
    "    print(f\"   æœ€ä½³epoch: {report['è®­ç»ƒç»“æœ']['æœ€ä½³epoch']}\")\n",
    "    print(f\"   æ€»è®­ç»ƒè½®æ•°: {report['è®­ç»ƒç»“æœ']['æ€»è®­ç»ƒepoch']}\")\n",
    "    \n",
    "    print(f\"\\nğŸ¤– æ¨¡å‹ä¿¡æ¯:\")\n",
    "    print(f\"   æ¶æ„: {report['æ¨¡å‹æ¶æ„']['åŸºç¡€æ¨¡å‹']}\")\n",
    "    print(f\"   å‚æ•°é‡: {report['æ¨¡å‹æ¶æ„']['æ€»å‚æ•°é‡']}\")\n",
    "    print(f\"   è¾“å…¥å°ºå¯¸: {report['æ¨¡å‹æ¶æ„']['è¾“å…¥å°ºå¯¸']}\")\n",
    "    print(f\"   è¾“å‡ºç±»åˆ«: {report['æ¨¡å‹æ¶æ„']['è¾“å‡ºç»´åº¦']}\")\n",
    "    \n",
    "    print(f\"\\nâš™ï¸ è®­ç»ƒé…ç½®:\")\n",
    "    print(f\"   è®¾å¤‡: {report['è®­ç»ƒé…ç½®']['è®¾å¤‡']}\")\n",
    "    print(f\"   ä¼˜åŒ–å™¨: {report['è®­ç»ƒé…ç½®']['ä¼˜åŒ–å™¨']}\")\n",
    "    print(f\"   å­¦ä¹ ç‡: {report['è®­ç»ƒé…ç½®']['åˆå§‹å­¦ä¹ ç‡']}\")\n",
    "    print(f\"   æ‰¹æ¬¡å¤§å°: {report['è®­ç»ƒé…ç½®']['æ‰¹æ¬¡å¤§å°']}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ æ•°æ®é›†:\")\n",
    "    print(f\"   ç±»åˆ«æ•°: {report['æ•°æ®é›†']['æ€»ç±»åˆ«æ•°']}\")\n",
    "    print(f\"   è®­ç»ƒé›†: {report['æ•°æ®é›†']['è®­ç»ƒé›†å¤§å°']} æ ·æœ¬\")\n",
    "    print(f\"   éªŒè¯é›†: {report['æ•°æ®é›†']['éªŒè¯é›†å¤§å°']} æ ·æœ¬\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ ç³»ç»Ÿç¯å¢ƒ:\")\n",
    "    print(f\"   PyTorch: {report['ç³»ç»Ÿç¯å¢ƒ']['PyTorchç‰ˆæœ¬']}\")\n",
    "    print(f\"   CUDA: {report['ç³»ç»Ÿç¯å¢ƒ']['CUDAå¯ç”¨']}\")\n",
    "    print(f\"   GPU: {report['ç³»ç»Ÿç¯å¢ƒ']['GPUè®¾å¤‡']}\")\n",
    "\n",
    "# é‡æ–°ç”Ÿæˆå®éªŒæŠ¥å‘Šï¼ˆä¿®å¤numpyæ•°ç»„åºåˆ—åŒ–é—®é¢˜ï¼‰\n",
    "experiment_report = generate_experiment_report(\n",
    "    model, history, class_names, model_dir, best_epoch, best_val_acc\n",
    ")\n",
    "\n",
    "# ä¿å­˜å®éªŒæŠ¥å‘Š\n",
    "json_path, txt_path = save_experiment_report(experiment_report, model_dir)\n",
    "\n",
    "# æ‰“å°æ‘˜è¦\n",
    "print_experiment_summary(experiment_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524025ec-7662-4aca-b181-f3f324964737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# å¢å¼ºæ•°æ®å¢å¼ºå’Œæ­£åˆ™åŒ–\n",
    "def setup_enhanced_data_transforms():\n",
    "    \"\"\"è®¾ç½®å¢å¼ºçš„æ•°æ®é¢„å¤„ç†å’Œå¢å¼ºè½¬æ¢\"\"\"\n",
    "    \n",
    "    # æ›´å¼ºçš„è®­ç»ƒæ•°æ®è½¬æ¢ï¼ˆåŒ…å«æ›´å¤šæ•°æ®å¢å¼ºï¼‰\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # éšæœºç¼©æ”¾è£å‰ª\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.05),  # æ·»åŠ å‚ç›´ç¿»è½¬\n",
    "        transforms.RandomRotation(15),  # å¢åŠ æ—‹è½¬è§’åº¦\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),  # å¢å¼ºé¢œè‰²æŠ–åŠ¨\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # éšæœºå¹³ç§»\n",
    "        transforms.RandomGrayscale(p=0.1),  # éšæœºç°åº¦åŒ–\n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),  # é«˜æ–¯æ¨¡ç³Š\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # éªŒè¯å’Œæµ‹è¯•æ•°æ®è½¬æ¢ï¼ˆä¸åŒ…å«æ•°æ®å¢å¼ºï¼‰\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "# åˆ›å»ºå¸¦Dropoutçš„ResNet18æ¨¡å‹\n",
    "def create_resnet18_with_dropout(num_classes, use_pretrained=True, dropout_rate=0.2):\n",
    "    \"\"\"åˆ›å»ºå¸¦Dropoutçš„ResNet18æ¨¡å‹\"\"\"\n",
    "    \n",
    "    model = models.resnet18(pretrained=use_pretrained)\n",
    "    \n",
    "    # ä¿®æ”¹æœ€åçš„å…¨è¿æ¥å±‚ï¼Œæ·»åŠ Dropout\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_rate),\n",
    "        nn.Linear(num_features, num_classes)\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… å¸¦Dropoutçš„ResNet18æ¨¡å‹åˆ›å»ºå®Œæˆ\")\n",
    "    print(f\"   Dropoutç‡: {dropout_rate}\")\n",
    "    print(f\"   è¾“å‡ºç±»åˆ«æ•°: {num_classes}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# å¯é€‰ï¼šå¦‚æœéœ€è¦é‡æ–°å¼€å§‹è®­ç»ƒï¼Œå¯ä»¥ä½¿ç”¨è¿™äº›å¢å¼ºæªæ–½\n",
    "print(\"\\nğŸ’¡ è¿‡æ‹Ÿåˆé˜²æ­¢æªæ–½å·²æ·»åŠ :\")\n",
    "print(\"   - æ›´å¼ºçš„æ•°æ®å¢å¼ºï¼ˆéšæœºç¼©æ”¾ã€å¹³ç§»ã€ç°åº¦åŒ–ã€é«˜æ–¯æ¨¡ç³Šï¼‰\")\n",
    "print(\"   - æ¨¡å‹æ·»åŠ Dropoutå±‚\")\n",
    "print(\"   - æ—©åœæœºåˆ¶ï¼ˆpatience=15ï¼‰\")\n",
    "print(\"   - ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦\")\n",
    "print(\"   - æ›´å¼ºçš„æƒé‡è¡°å‡ï¼ˆ1e-3ï¼‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7731f066-9758-4b20-a51f-98b3c05405e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ æ‰‹åŠ¿åˆ†ç±»ResNet18 æ¨¡å‹å¤§å°åˆ†æ\n",
      "==================================================\n",
      "ğŸ“Š å‚æ•°ç»Ÿè®¡:\n",
      "   æ€»å‚æ•°: 11,181,129\n",
      "   å¯è®­ç»ƒå‚æ•°: 11,181,129\n",
      "   ä¸å¯è®­ç»ƒå‚æ•°: 0\n",
      "   å¯è®­ç»ƒå‚æ•°å æ¯”: 100.00%\n",
      "\n",
      "ğŸ’¾ å­˜å‚¨å¤§å°ä¼°ç®— (FP32):\n",
      "   å­—èŠ‚: 44,724,516 B\n",
      "   å…†å­—èŠ‚: 42.65 MB\n",
      "   åƒå…†å­—èŠ‚: 0.0417 GB\n",
      "\n",
      "ğŸ¯ ä¸åŒç²¾åº¦ä¸‹çš„å­˜å‚¨å¤§å°:\n",
      "   FP32 (32ä½): 42.65 MB\n",
      "   FP16 (16ä½): 21.33 MB\n",
      "   INT8 (8ä½): 10.66 MB\n",
      "   INT4 (4ä½): 5.33 MB\n"
     ]
    }
   ],
   "source": [
    "def analyze_model_size(model, model_name=\"ResNet18\"):\n",
    "    \"\"\"åˆ†ææ¨¡å‹çš„å¤§å°ï¼ˆå‚æ•°æ•°é‡å’Œå­˜å‚¨å¤§å°ï¼‰\"\"\"\n",
    "    print(f\"ğŸ“ {model_name} æ¨¡å‹å¤§å°åˆ†æ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # è®¡ç®—æ€»å‚æ•°å’Œå¯è®­ç»ƒå‚æ•°\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    non_trainable_params = total_params - trainable_params\n",
    "    \n",
    "    # è®¡ç®—å­˜å‚¨å¤§å°ï¼ˆå‡è®¾32ä½æµ®ç‚¹æ•°ï¼Œæ¯ä¸ªå‚æ•°4å­—èŠ‚ï¼‰\n",
    "    storage_size_bytes = total_params * 4\n",
    "    storage_size_mb = storage_size_bytes / (1024 ** 2)\n",
    "    storage_size_gb = storage_size_bytes / (1024 ** 3)\n",
    "    \n",
    "    print(f\"ğŸ“Š å‚æ•°ç»Ÿè®¡:\")\n",
    "    print(f\"   æ€»å‚æ•°: {total_params:,}\")\n",
    "    print(f\"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}\")\n",
    "    print(f\"   ä¸å¯è®­ç»ƒå‚æ•°: {non_trainable_params:,}\")\n",
    "    print(f\"   å¯è®­ç»ƒå‚æ•°å æ¯”: {trainable_params/total_params*100:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ å­˜å‚¨å¤§å°ä¼°ç®— (FP32):\")\n",
    "    print(f\"   å­—èŠ‚: {storage_size_bytes:,} B\")\n",
    "    print(f\"   å…†å­—èŠ‚: {storage_size_mb:.2f} MB\")\n",
    "    print(f\"   åƒå…†å­—èŠ‚: {storage_size_gb:.4f} GB\")\n",
    "    \n",
    "    # ä¸åŒç²¾åº¦ä¸‹çš„å­˜å‚¨å¤§å°\n",
    "    print(f\"\\nğŸ¯ ä¸åŒç²¾åº¦ä¸‹çš„å­˜å‚¨å¤§å°:\")\n",
    "    precisions = {\n",
    "        \"FP32 (32ä½)\": 4,\n",
    "        \"FP16 (16ä½)\": 2,\n",
    "        \"INT8 (8ä½)\": 1,\n",
    "        \"INT4 (4ä½)\": 0.5\n",
    "    }\n",
    "    \n",
    "    for precision, bytes_per_param in precisions.items():\n",
    "        size_bytes = total_params * bytes_per_param\n",
    "        size_mb = size_bytes / (1024 ** 2)\n",
    "        print(f\"   {precision}: {size_mb:.2f} MB\")\n",
    "    \n",
    "    return total_params, storage_size_mb\n",
    "\n",
    "# åˆ†æå½“å‰æ¨¡å‹å¤§å°\n",
    "total_params, storage_size_mb = analyze_model_size(model, \"æ‰‹åŠ¿åˆ†ç±»ResNet18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7910d026-6ac0-4cbe-b0a9-ba06da30e83e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” æŒ‰å±‚åˆ†æå‚æ•°åˆ†å¸ƒ\n",
      "==================================================\n",
      "å±‚åç§°                                                 å‚æ•°æ•°é‡       å æ¯”\n",
      "----------------------------------------------------------------------\n",
      "layer4.0.conv2.weight                          2,359,296   21.10%\n",
      "layer4.1.conv1.weight                          2,359,296   21.10%\n",
      "layer4.1.conv2.weight                          2,359,296   21.10%\n",
      "layer4.0.conv1.weight                          1,179,648   10.55%\n",
      "layer3.0.conv2.weight                            589,824    5.28%\n",
      "layer3.1.conv1.weight                            589,824    5.28%\n",
      "layer3.1.conv2.weight                            589,824    5.28%\n",
      "layer3.0.conv1.weight                            294,912    2.64%\n",
      "layer2.0.conv2.weight                            147,456    1.32%\n",
      "layer2.1.conv1.weight                            147,456    1.32%\n",
      "layer2.1.conv2.weight                            147,456    1.32%\n",
      "layer4.0.downsample.0.weight                     131,072    1.17%\n",
      "layer2.0.conv1.weight                             73,728    0.66%\n",
      "layer1.0.conv1.weight                             36,864    0.33%\n",
      "layer1.0.conv2.weight                             36,864    0.33%\n",
      "layer1.1.conv1.weight                             36,864    0.33%\n",
      "layer1.1.conv2.weight                             36,864    0.33%\n",
      "layer3.0.downsample.0.weight                      32,768    0.29%\n",
      "conv1.weight                                       9,408    0.08%\n",
      "layer2.0.downsample.0.weight                       8,192    0.07%\n",
      "\n",
      "ğŸ“ˆ æŒ‰å±‚ç±»å‹æ±‡æ€»:\n",
      "----------------------------------------\n",
      "   layer4             8,393,728    75.1%\n",
      "   layer3             2,099,712    18.8%\n",
      "   layer2               525,568     4.7%\n",
      "   layer1               147,968     1.3%\n",
      "   conv1                  9,408     0.1%\n",
      "   fc                     4,617     0.0%\n",
      "   bn1                      128     0.0%\n"
     ]
    }
   ],
   "source": [
    "def analyze_model_by_layers(model):\n",
    "    \"\"\"æŒ‰å±‚åˆ†ææ¨¡å‹çš„å‚æ•°åˆ†å¸ƒ\"\"\"\n",
    "    print(f\"\\nğŸ” æŒ‰å±‚åˆ†æå‚æ•°åˆ†å¸ƒ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    layer_stats = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            layer_type = name.split('.')[0]\n",
    "            param_count = param.numel()\n",
    "            layer_stats.append((name, layer_type, param_count, param.requires_grad))\n",
    "    \n",
    "    # æŒ‰å‚æ•°æ•°é‡æ’åº\n",
    "    layer_stats.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    print(f\"{'å±‚åç§°':<40} {'å‚æ•°æ•°é‡':>15} {'å æ¯”':>8}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    for name, layer_type, param_count, trainable in layer_stats[:20]:  # æ˜¾ç¤ºå‰20å±‚\n",
    "        percentage = (param_count / total_params) * 100\n",
    "        print(f\"{name:<40} {param_count:>15,} {percentage:>7.2f}%\")\n",
    "    \n",
    "    # æŒ‰å±‚ç±»å‹æ±‡æ€»\n",
    "    print(f\"\\nğŸ“ˆ æŒ‰å±‚ç±»å‹æ±‡æ€»:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    layer_type_stats = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            layer_type = name.split('.')[0]\n",
    "            param_count = param.numel()\n",
    "            layer_type_stats[layer_type] = layer_type_stats.get(layer_type, 0) + param_count\n",
    "    \n",
    "    for layer_type, param_count in sorted(layer_type_stats.items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (param_count / total_params) * 100\n",
    "        print(f\"   {layer_type:<15} {param_count:>12,} {percentage:>7.1f}%\")\n",
    "\n",
    "# æŒ‰å±‚åˆ†ææ¨¡å‹\n",
    "analyze_model_by_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1936cd1f-7185-48df-87ac-05d234ced992",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§  æ¨ç†å†…å­˜å ç”¨ä¼°ç®—\n",
      "==================================================\n",
      "å‚æ•°å†…å­˜ (FP32): 42.65 MB\n",
      "æ¿€æ´»å†…å­˜ä¼°ç®—: 12.80 MB\n",
      "æ€»å†…å­˜ä¼°ç®—: 55.45 MB\n",
      "\n",
      "ğŸ“¦ ä¸åŒæ‰¹å¤„ç†å¤§å°çš„å†…å­˜éœ€æ±‚:\n",
      "   æ‰¹å¤„ç†å¤§å° 1: 55.45 MB\n",
      "   æ‰¹å¤„ç†å¤§å° 8: 443.59 MB\n",
      "   æ‰¹å¤„ç†å¤§å° 16: 887.17 MB\n",
      "   æ‰¹å¤„ç†å¤§å° 32: 1774.35 MB\n",
      "   æ‰¹å¤„ç†å¤§å° 64: 3548.70 MB\n"
     ]
    }
   ],
   "source": [
    "def estimate_inference_memory(model, input_size=(1, 3, 224, 224)):\n",
    "    \"\"\"ä¼°ç®—æ¨¡å‹æ¨ç†æ—¶çš„å†…å­˜å ç”¨\"\"\"\n",
    "    print(f\"\\nğŸ§  æ¨ç†å†…å­˜å ç”¨ä¼°ç®—\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ä¼°ç®—å‚æ•°å†…å­˜ï¼ˆFP32ï¼‰\n",
    "    param_memory = sum(p.numel() * 4 for p in model.parameters())  # 4å­—èŠ‚æ¯å‚æ•°\n",
    "    \n",
    "    # ä¼°ç®—å‰å‘ä¼ æ’­çš„æ¿€æ´»å†…å­˜\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿè¾“å…¥\n",
    "        dummy_input = torch.randn(*input_size).to(device)\n",
    "        \n",
    "        # è¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­æ¥ä¼°ç®—æ¿€æ´»å†…å­˜\n",
    "        output = model(dummy_input)\n",
    "        \n",
    "        # è¿™é‡Œæˆ‘ä»¬ç®€å•ä¼°ç®—ï¼šå‡è®¾æ¿€æ´»å†…å­˜å¤§çº¦æ˜¯å‚æ•°å†…å­˜çš„10-50%\n",
    "        # å®é™…å€¼å–å†³äºç½‘ç»œç»“æ„å’Œæ‰¹å¤„ç†å¤§å°\n",
    "        activation_memory_estimate = param_memory * 0.3  # 30%çš„ä¼°ç®—\n",
    "    \n",
    "    total_memory_estimate = param_memory + activation_memory_estimate\n",
    "    \n",
    "    print(f\"å‚æ•°å†…å­˜ (FP32): {param_memory/1024**2:.2f} MB\")\n",
    "    print(f\"æ¿€æ´»å†…å­˜ä¼°ç®—: {activation_memory_estimate/1024**2:.2f} MB\")\n",
    "    print(f\"æ€»å†…å­˜ä¼°ç®—: {total_memory_estimate/1024**2:.2f} MB\")\n",
    "    \n",
    "    # ä¸åŒæ‰¹å¤„ç†å¤§å°çš„å½±å“\n",
    "    print(f\"\\nğŸ“¦ ä¸åŒæ‰¹å¤„ç†å¤§å°çš„å†…å­˜éœ€æ±‚:\")\n",
    "    batch_sizes = [1, 8, 16, 32, 64]\n",
    "    for batch_size in batch_sizes:\n",
    "        batch_memory = total_memory_estimate * batch_size\n",
    "        print(f\"   æ‰¹å¤„ç†å¤§å° {batch_size}: {batch_memory/1024**2:.2f} MB\")\n",
    "    \n",
    "    return total_memory_estimate\n",
    "\n",
    "# ä¼°ç®—æ¨ç†å†…å­˜\n",
    "inference_memory = estimate_inference_memory(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bedfc95-f115-44e5-a8c0-359b648e7517",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ† ä¸å…¶ä»–æ¨¡å‹æ¯”è¾ƒ\n",
      "==================================================\n",
      "æ¨¡å‹                                   å‚æ•°æ•°é‡       ç›¸å¯¹å¤§å°\n",
      "-------------------------------------------------------\n",
      "MobileNetV2                     3,504,872      0.31x\n",
      "EfficientNet-B0                 5,288,548      0.47x\n",
      "æ‰‹åŠ¿åˆ†ç±»ResNet18                   11,181,129      1.00x\n",
      "ResNet18                       11,689,512      1.05x\n",
      "ResNet34                       21,797,672      1.95x\n",
      "ResNet50                       25,557,032      2.29x\n",
      "AlexNet                        61,100,840      5.46x\n",
      "VGG16                         138,357,544     12.37x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 21442 (\\N{CJK UNIFIED IDEOGRAPH-53C2}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 23545 (\\N{CJK UNIFIED IDEOGRAPH-5BF9}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 23610 (\\N{CJK UNIFIED IDEOGRAPH-5C3A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 25163 (\\N{CJK UNIFIED IDEOGRAPH-624B}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 21183 (\\N{CJK UNIFIED IDEOGRAPH-52BF}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 31867 (\\N{CJK UNIFIED IDEOGRAPH-7C7B}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 27169 (\\N{CJK UNIFIED IDEOGRAPH-6A21}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 27604 (\\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 36739 (\\N{CJK UNIFIED IDEOGRAPH-8F83}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:55: UserWarning: Glyph 24615 (\\N{CJK UNIFIED IDEOGRAPH-6027}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 25163 (\\N{CJK UNIFIED IDEOGRAPH-624B}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 21183 (\\N{CJK UNIFIED IDEOGRAPH-52BF}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 31867 (\\N{CJK UNIFIED IDEOGRAPH-7C7B}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 27169 (\\N{CJK UNIFIED IDEOGRAPH-6A21}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 21442 (\\N{CJK UNIFIED IDEOGRAPH-53C2}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 27604 (\\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 36739 (\\N{CJK UNIFIED IDEOGRAPH-8F83}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 23545 (\\N{CJK UNIFIED IDEOGRAPH-5BF9}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 23610 (\\N{CJK UNIFIED IDEOGRAPH-5C3A}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_4454/1567601724.py:56: UserWarning: Glyph 24615 (\\N{CJK UNIFIED IDEOGRAPH-6027}) missing from current font.\n",
      "  plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 25163 (\\N{CJK UNIFIED IDEOGRAPH-624B}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 21183 (\\N{CJK UNIFIED IDEOGRAPH-52BF}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 31867 (\\N{CJK UNIFIED IDEOGRAPH-7C7B}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 27169 (\\N{CJK UNIFIED IDEOGRAPH-6A21}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 21442 (\\N{CJK UNIFIED IDEOGRAPH-53C2}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 27604 (\\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 36739 (\\N{CJK UNIFIED IDEOGRAPH-8F83}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 23545 (\\N{CJK UNIFIED IDEOGRAPH-5BF9}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 23610 (\\N{CJK UNIFIED IDEOGRAPH-5C3A}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 24615 (\\N{CJK UNIFIED IDEOGRAPH-6027}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… æ¨¡å‹æ¯”è¾ƒå›¾è¡¨å·²ä¿å­˜: /mnt/MCP/gesture_models/model_size_comparison.png\n"
     ]
    }
   ],
   "source": [
    "def compare_with_other_models():\n",
    "    \"\"\"ä¸å…¶ä»–å¸¸è§æ¨¡å‹æ¯”è¾ƒå¤§å°\"\"\"\n",
    "    print(f\"\\nğŸ† ä¸å…¶ä»–æ¨¡å‹æ¯”è¾ƒ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # å¸¸è§æ¨¡å‹çš„å‚æ•°æ•°é‡ï¼ˆè¿‘ä¼¼å€¼ï¼‰\n",
    "    model_comparison = {\n",
    "        \"æ‰‹åŠ¿åˆ†ç±»ResNet18\": total_params,\n",
    "        \"ResNet18\": 11689512,\n",
    "        \"ResNet34\": 21797672,\n",
    "        \"ResNet50\": 25557032,\n",
    "        \"MobileNetV2\": 3504872,\n",
    "        \"EfficientNet-B0\": 5288548,\n",
    "        \"VGG16\": 138357544,\n",
    "        \"AlexNet\": 61100840\n",
    "    }\n",
    "    \n",
    "    print(f\"{'æ¨¡å‹':<25} {'å‚æ•°æ•°é‡':>15} {'ç›¸å¯¹å¤§å°':>10}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    our_model_params = model_comparison[\"æ‰‹åŠ¿åˆ†ç±»ResNet18\"]\n",
    "    \n",
    "    for model_name, params in sorted(model_comparison.items(), key=lambda x: x[1]):\n",
    "        relative_size = params / our_model_params\n",
    "        print(f\"{model_name:<25} {params:>15,} {relative_size:>9.2f}x\")\n",
    "    \n",
    "    # å¯è§†åŒ–æ¯”è¾ƒ\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    models = list(model_comparison.keys())\n",
    "    params = list(model_comparison.values())\n",
    "    \n",
    "    # å¯¹æ•°å°ºåº¦\n",
    "    plt.subplot(1, 2, 1)\n",
    "    bars = plt.barh(models, params, color='skyblue')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('å‚æ•°æ•°é‡ (å¯¹æ•°å°ºåº¦)')\n",
    "    plt.title('æ¨¡å‹å‚æ•°æ•°é‡æ¯”è¾ƒ (å¯¹æ•°å°ºåº¦)')\n",
    "    \n",
    "    # ä¸ºæˆ‘ä»¬çš„æ¨¡å‹ç€è‰²\n",
    "    for i, bar in enumerate(bars):\n",
    "        if models[i] == \"æ‰‹åŠ¿åˆ†ç±»ResNet18\":\n",
    "            bar.set_color('orange')\n",
    "    \n",
    "    # çº¿æ€§å°ºåº¦\n",
    "    plt.subplot(1, 2, 2)\n",
    "    bars = plt.barh(models, params, color='lightgreen')\n",
    "    plt.xlabel('å‚æ•°æ•°é‡')\n",
    "    plt.title('æ¨¡å‹å‚æ•°æ•°é‡æ¯”è¾ƒ (çº¿æ€§å°ºåº¦)')\n",
    "    \n",
    "    # ä¸ºæˆ‘ä»¬çš„æ¨¡å‹ç€è‰²\n",
    "    for i, bar in enumerate(bars):\n",
    "        if models[i] == \"æ‰‹åŠ¿åˆ†ç±»ResNet18\":\n",
    "            bar.set_color('orange')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(model_dir, 'model_size_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nâœ… æ¨¡å‹æ¯”è¾ƒå›¾è¡¨å·²ä¿å­˜: {os.path.join(model_dir, 'model_size_comparison.png')}\")\n",
    "\n",
    "# ä¸å…¶ä»–æ¨¡å‹æ¯”è¾ƒ\n",
    "compare_with_other_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbec3ab9-4e4f-4d63-bf8d-cc658fcc51b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ ç”Ÿæˆå®Œæ•´çš„æ¨¡å‹å¤§å°æŠ¥å‘Š\n",
      "==================================================\n",
      "ğŸ“ ResNet18 æ¨¡å‹å¤§å°åˆ†æ\n",
      "==================================================\n",
      "ğŸ“Š å‚æ•°ç»Ÿè®¡:\n",
      "   æ€»å‚æ•°: 11,181,129\n",
      "   å¯è®­ç»ƒå‚æ•°: 11,181,129\n",
      "   ä¸å¯è®­ç»ƒå‚æ•°: 0\n",
      "   å¯è®­ç»ƒå‚æ•°å æ¯”: 100.00%\n",
      "\n",
      "ğŸ’¾ å­˜å‚¨å¤§å°ä¼°ç®— (FP32):\n",
      "   å­—èŠ‚: 44,724,516 B\n",
      "   å…†å­—èŠ‚: 42.65 MB\n",
      "   åƒå…†å­—èŠ‚: 0.0417 GB\n",
      "\n",
      "ğŸ¯ ä¸åŒç²¾åº¦ä¸‹çš„å­˜å‚¨å¤§å°:\n",
      "   FP32 (32ä½): 42.65 MB\n",
      "   FP16 (16ä½): 21.33 MB\n",
      "   INT8 (8ä½): 10.66 MB\n",
      "   INT4 (4ä½): 5.33 MB\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_and_check_model_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m report\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# ç”Ÿæˆå®Œæ•´æŠ¥å‘Š\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m model_size_report \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_model_size_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 8\u001b[0m, in \u001b[0;36mgenerate_model_size_report\u001b[0;34m(model, model_dir)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# æ”¶é›†æ‰€æœ‰ä¿¡æ¯\u001b[39;00m\n\u001b[1;32m      7\u001b[0m total_params, storage_size_mb \u001b[38;5;241m=\u001b[39m analyze_model_size(model)\n\u001b[0;32m----> 8\u001b[0m full_model_path, state_dict_path \u001b[38;5;241m=\u001b[39m \u001b[43msave_and_check_model_size\u001b[49m(model, model_dir)\n\u001b[1;32m      9\u001b[0m inference_memory \u001b[38;5;241m=\u001b[39m estimate_inference_memory(model)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# åˆ›å»ºæŠ¥å‘Š\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_and_check_model_size' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_model_size_report(model, model_dir):\n",
    "    \"\"\"ç”Ÿæˆå®Œæ•´çš„æ¨¡å‹å¤§å°æŠ¥å‘Š\"\"\"\n",
    "    print(f\"\\nğŸ“‹ ç”Ÿæˆå®Œæ•´çš„æ¨¡å‹å¤§å°æŠ¥å‘Š\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # æ”¶é›†æ‰€æœ‰ä¿¡æ¯\n",
    "    total_params, storage_size_mb = analyze_model_size(model)\n",
    "    full_model_path, state_dict_path = save_and_check_model_size(model, model_dir)\n",
    "    inference_memory = estimate_inference_memory(model)\n",
    "    \n",
    "    # åˆ›å»ºæŠ¥å‘Š\n",
    "    report = {\n",
    "        \"ç”Ÿæˆæ—¶é—´\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"æ¨¡å‹åç§°\": \"æ‰‹åŠ¿åˆ†ç±»ResNet18\",\n",
    "        \"å‚æ•°ç»Ÿè®¡\": {\n",
    "            \"æ€»å‚æ•°\": f\"{total_params:,}\",\n",
    "            \"å¯è®­ç»ƒå‚æ•°\": f\"{sum(p.numel() for p in model.parameters() if p.requires_grad):,}\",\n",
    "            \"ä¸å¯è®­ç»ƒå‚æ•°\": f\"{sum(p.numel() for p in model.parameters() if not p.requires_grad):,}\"\n",
    "        },\n",
    "        \"å­˜å‚¨å¤§å°\": {\n",
    "            \"ç†è®ºå¤§å° (FP32)\": f\"{storage_size_mb:.2f} MB\",\n",
    "            \"å®Œæ•´æ¨¡å‹æ–‡ä»¶\": f\"{os.path.getsize(full_model_path)/1024**2:.2f} MB\",\n",
    "            \"çŠ¶æ€å­—å…¸æ–‡ä»¶\": f\"{os.path.getsize(state_dict_path)/1024**2:.2f} MB\"\n",
    "        },\n",
    "        \"å†…å­˜ä¼°ç®—\": {\n",
    "            \"æ¨ç†å†…å­˜ (æ‰¹å¤„ç†å¤§å°1)\": f\"{inference_memory/1024**2:.2f} MB\",\n",
    "            \"æ‰¹å¤„ç†å¤§å°8\": f\"{inference_memory * 8/1024**2:.2f} MB\",\n",
    "            \"æ‰¹å¤„ç†å¤§å°16\": f\"{inference_memory * 16/1024**2:.2f} MB\"\n",
    "        },\n",
    "        \"ä¼˜åŒ–å»ºè®®\": [\n",
    "            \"è€ƒè™‘ä½¿ç”¨FP16ç²¾åº¦å‡å°‘50%å†…å­˜å ç”¨\",\n",
    "            \"å¯¹äºç§»åŠ¨è®¾å¤‡ï¼Œè€ƒè™‘é‡åŒ–åˆ°INT8\",\n",
    "            \"ä½¿ç”¨æ¨¡å‹å‰ªæå‡å°‘å‚æ•°æ•°é‡\",\n",
    "            \"è€ƒè™‘ä½¿ç”¨æ›´è½»é‡çš„æ¶æ„å¦‚MobileNet\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # ä¿å­˜æŠ¥å‘Š\n",
    "    report_path = os.path.join(model_dir, \"model_size_report.json\")\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # æ‰“å°æŠ¥å‘Šæ‘˜è¦\n",
    "    print(f\"\\nğŸ¯ æ¨¡å‹å¤§å°æŠ¥å‘Šæ‘˜è¦:\")\n",
    "    print(f\"   æ€»å‚æ•°: {report['å‚æ•°ç»Ÿè®¡']['æ€»å‚æ•°']}\")\n",
    "    print(f\"   å­˜å‚¨å¤§å°: {report['å­˜å‚¨å¤§å°']['çŠ¶æ€å­—å…¸æ–‡ä»¶']}\")\n",
    "    print(f\"   æ¨ç†å†…å­˜: {report['å†…å­˜ä¼°ç®—']['æ¨ç†å†…å­˜ (æ‰¹å¤„ç†å¤§å°1)']}\")\n",
    "    print(f\"   å®Œæ•´æŠ¥å‘Š: {report_path}\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# ç”Ÿæˆå®Œæ•´æŠ¥å‘Š\n",
    "model_size_report = generate_model_size_report(model, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a804e48-3e47-4230-ad95-a28c693ca716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
